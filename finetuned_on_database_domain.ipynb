{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPdyPIwbwl3LGWSO/ZouKBu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MYVirajani/AI-Exam-Evaluation-System/blob/Fine-tunned-model/finetuned_on_database_domain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwgix9NWrdCV",
        "outputId": "e20105ed-fb93-4cca-cd01-a5fbd41ae0ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLaMA-Factory'...\n",
            "remote: Enumerating objects: 23952, done.\u001b[K\n",
            "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 23952 (delta 100), reused 82 (delta 82), pack-reused 23809 (from 3)\u001b[K\n",
            "Receiving objects: 100% (23952/23952), 49.37 MiB | 16.39 MiB/s, done.\n",
            "Resolving deltas: 100% (17306/17306), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/hiyouga/LLaMA-Factory.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd LLaMA-Factory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHAKR7Fnrgjq",
        "outputId": "df9b73a2-1142-4ade-8792-d3acfda63494"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLaMA-Factory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtqYryhergg7",
        "outputId": "667533b6-7926-47a8-90a0-06c8a8363849"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLaMA-Factory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX-VGohurgd6",
        "outputId": "6bda77be-b842-48ed-d52f-44aca6af0e1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignoring transformers: markers 'sys_platform == \"darwin\"' don't match your environment\n",
            "Requirement already satisfied: transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (4.52.4)\n",
            "Collecting datasets<=3.6.0,>=2.16.0 (from -r requirements.txt (line 3))\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate<=1.7.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.7.0)\n",
            "Requirement already satisfied: peft<=0.15.2,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.15.2)\n",
            "Collecting trl<=0.9.6,>=0.8.6 (from -r requirements.txt (line 6))\n",
            "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: tokenizers<=0.21.1,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.21.1)\n",
            "Requirement already satisfied: gradio<=5.31.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (5.31.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.15.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.9.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (5.29.5)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.34.3)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (0.115.12)\n",
            "Collecting sse-starlette (from -r requirements.txt (line 16))\n",
            "  Downloading sse_starlette-2.3.6-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (3.10.0)\n",
            "Collecting fire (from -r requirements.txt (line 18))\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (2.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (6.0.2)\n",
            "Collecting numpy<2.0.0 (from -r requirements.txt (line 22))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<=2.10.6 (from -r requirements.txt (line 23))\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (2.2.2)\n",
            "Collecting av (from -r requirements.txt (line 25))\n",
            "  Downloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (0.11.0)\n",
            "Collecting tyro<0.9.0 (from -r requirements.txt (line 27))\n",
            "  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0->-r requirements.txt (line 1)) (0.32.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0->-r requirements.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->-r requirements.txt (line 3)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->-r requirements.txt (line 3)) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->-r requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->-r requirements.txt (line 3)) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->-r requirements.txt (line 3))\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4)) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4)) (2.6.0+cu124)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (3.10.18)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (11.2.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (4.14.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (15.0.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->-r requirements.txt (line 14)) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn->-r requirements.txt (line 14)) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (2.9.0.post0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->-r requirements.txt (line 18)) (3.1.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->-r requirements.txt (line 19)) (4.9.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.10.6->-r requirements.txt (line 23)) (0.7.0)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<=2.10.6->-r requirements.txt (line 23))\n",
            "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 24)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 24)) (2025.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 26)) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 26)) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 26)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 26)) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 26)) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 26)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 26)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 26)) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 26)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 26)) (1.1.0)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->-r requirements.txt (line 27)) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->-r requirements.txt (line 27)) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro<0.9.0->-r requirements.txt (line 27))\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->-r requirements.txt (line 3)) (3.11.15)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (1.0.9)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0->-r requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 26)) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 26)) (4.3.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro<0.9.0->-r requirements.txt (line 27)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro<0.9.0->-r requirements.txt (line 27)) (2.19.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 26)) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 26)) (1.17.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4)) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->-r requirements.txt (line 8)) (1.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->-r requirements.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->-r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->-r requirements.txt (line 3)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->-r requirements.txt (line 3)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->-r requirements.txt (line 3)) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->-r requirements.txt (line 3)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->-r requirements.txt (line 3)) (1.20.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 26)) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->-r requirements.txt (line 27)) (0.1.2)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-2.3.6-py3-none-any.whl (10 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.8.14-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=a57f353bc11255f53e714e01abbd06f3463ef2952358e9c9111060d31e7551bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: shtab, pydantic-core, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fsspec, fire, av, sse-starlette, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, datasets, trl\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.5\n",
            "    Uninstalling pydantic-2.11.5:\n",
            "      Successfully uninstalled pydantic-2.11.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed av-14.4.0 datasets-3.6.0 fire-0.7.0 fsspec-2025.3.0 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydantic-2.10.6 pydantic-core-2.27.2 shtab-1.7.2 sse-starlette-2.3.6 trl-0.9.6 tyro-0.8.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes transformers_stream_generator huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDzk9UHKrgbe",
        "outputId": "3f0a92dc-65cd-4760-c39e-7bdd46d35c15"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Collecting transformers_stream_generator\n",
            "  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.32.4)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: transformers>=4.26.1 in /usr/local/lib/python3.11/dist-packages (from transformers_stream_generator) (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.5.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers_stream_generator\n",
            "  Building wheel for transformers_stream_generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12426 sha256=f1f93e9c1749b48f410607654be7aa56af95d87c77149d1e72f426d1f8a8d56b\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/e8/f0/b3c58c12d1ffe60bcc8c7d121115f26b2c1878653edfca48db\n",
            "Successfully built transformers_stream_generator\n",
            "Installing collected packages: bitsandbytes, transformers_stream_generator\n",
            "Successfully installed bitsandbytes-0.46.0 transformers_stream_generator-0.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGORSXXZrgYp",
        "outputId": "863dbdf0-7052-4666-8392-2bfa40166546"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `finetune token` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `finetune token`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-KqV9HPrgV9",
        "outputId": "97d87cd7-224d-4e52-9914-916fa56047c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/LLaMA-Factory\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (4.52.4)\n",
            "Requirement already satisfied: datasets<=3.6.0,>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (3.6.0)\n",
            "Requirement already satisfied: accelerate<=1.7.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (1.7.0)\n",
            "Requirement already satisfied: peft<=0.15.2,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.15.2)\n",
            "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.9.6)\n",
            "Requirement already satisfied: tokenizers<=0.21.1,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.21.1)\n",
            "Requirement already satisfied: gradio<=5.31.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (5.31.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (1.15.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.9.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (5.29.5)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.34.3)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.115.12)\n",
            "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (2.3.6)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (3.10.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.7.0)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (2.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (6.0.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (1.26.4)\n",
            "Requirement already satisfied: pydantic<=2.10.6 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (2.10.6)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (2.2.2)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (14.4.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.11.0)\n",
            "Requirement already satisfied: tyro<0.9.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.3.dev0) (0.8.14)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (0.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (2025.3.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (4.9.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (3.10.18)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (11.2.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (4.14.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (15.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory==0.9.3.dev0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory==0.9.3.dev0) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.10.6->llamafactory==0.9.3.dev0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.10.6->llamafactory==0.9.3.dev0) (2.27.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0->llamafactory==0.9.3.dev0) (2024.11.6)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory==0.9.3.dev0) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory==0.9.3.dev0) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory==0.9.3.dev0) (1.7.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llamafactory==0.9.3.dev0) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llamafactory==0.9.3.dev0) (0.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->llamafactory==0.9.3.dev0) (3.1.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.3.dev0) (1.1.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->llamafactory==0.9.3.dev0) (4.9.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (1.3.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (3.11.15)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (1.0.9)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (1.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->llamafactory==0.9.3.dev0) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->llamafactory==0.9.3.dev0) (4.3.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (2.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.3.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.3.dev0) (2.19.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->llamafactory==0.9.3.dev0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->llamafactory==0.9.3.dev0) (1.17.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate<=1.7.0,>=0.34.0->llamafactory==0.9.3.dev0) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.3.dev0) (1.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.3.dev0) (1.20.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory==0.9.3.dev0) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.3.dev0) (0.1.2)\n",
            "Building wheels for collected packages: llamafactory\n",
            "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llamafactory: filename=llamafactory-0.9.3.dev0-0.editable-py3-none-any.whl size=27520 sha256=21243c1dbc9734cb21216b586b0f5d984d296041a1ea8b313da23158390ebab0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w7_eeu6u/wheels/bd/34/05/1e3cb4b8f20c20631b411dc5157b4b150850c03496fa96c2c4\n",
            "Successfully built llamafactory\n",
            "Installing collected packages: llamafactory\n",
            "Successfully installed llamafactory-0.9.3.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python src/webui.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSw6Yfu3rgS6",
        "outputId": "1be1dfc8-a285-42b9-c261-24a2c8805951"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-09 08:00:16.470781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749456016.842737    1891 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749456016.943421    1891 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-09 08:00:17.675108: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Visit http://ip:port for Web UI, e.g., http://127.0.0.1:7860\n",
            "* Running on local URL:  http://0.0.0.0:7860\n",
            "* Running on public URL: https://6edc779b22104c167c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "2025-06-09 08:10:26.131283: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749456626.167753    4426 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749456626.177467    4426 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[WARNING|2025-06-09 08:10:33] llamafactory.hparams.parser:148 >> We recommend enable `upcast_layernorm` in quantized training.\n",
            "[INFO|2025-06-09 08:10:33] llamafactory.hparams.parser:401 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: torch.bfloat16\n",
            "tokenizer_config.json: 100% 141k/141k [00:00<00:00, 38.0MB/s]\n",
            "tokenizer.model: 100% 587k/587k [00:00<00:00, 67.4MB/s]\n",
            "tokenizer.json: 100% 1.96M/1.96M [00:01<00:00, 1.32MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.80MB/s]\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 08:10:37,635 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 08:10:37,635 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 08:10:37,635 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 08:10:37,635 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 08:10:37,636 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 08:10:37,636 >> loading file chat_template.jinja from cache at None\n",
            "config.json: 100% 601/601 [00:00<00:00, 4.61MB/s]\n",
            "[INFO|configuration_utils.py:698] 2025-06-09 08:10:40,143 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/config.json\n",
            "[INFO|configuration_utils.py:770] 2025-06-09 08:10:40,147 >> Model config MistralConfig {\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": null,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32768\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 08:10:40,672 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 08:10:40,672 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 08:10:40,672 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 08:10:40,672 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 08:10:40,672 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 08:10:40,672 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|2025-06-09 08:10:41] llamafactory.data.template:143 >> Add pad token: </s>\n",
            "[INFO|2025-06-09 08:10:41] llamafactory.data.loader:143 >> Loading dataset anasmkh/DB_Engineering...\n",
            "README.md: 100% 533/533 [00:00<00:00, 4.08MB/s]\n",
            "train-00000-of-00001.parquet: 100% 244k/244k [00:00<00:00, 30.4MB/s]\n",
            "test-00000-of-00001.parquet: 100% 77.2k/77.2k [00:00<00:00, 27.0MB/s]\n",
            "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "WARNING:datasets.builder:Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 100% 516/516 [00:00<00:00, 6208.29 examples/s]\n",
            "Setting num_proc from 16 back to 1 for the test split to disable multiprocessing as it only contains one shard.\n",
            "WARNING:datasets.builder:Setting num_proc from 16 back to 1 for the test split to disable multiprocessing as it only contains one shard.\n",
            "Generating test split: 100% 129/129 [00:00<00:00, 38978.84 examples/s]\n",
            "Converting format of dataset (num_proc=16): 100% 516/516 [00:00<00:00, 783.23 examples/s]\n",
            "Running tokenizer on dataset (num_proc=16): 100% 516/516 [00:04<00:00, 114.27 examples/s]\n",
            "training example:\n",
            "input_ids:\n",
            "[1, 3, 2370, 1309, 2320, 5951, 10063, 29510, 29481, 2320, 1824, 1080, 3227, 29600, 1115, 22297, 1122, 18041, 12874, 29493, 1072, 1535, 1228, 1040, 2713, 2685, 1465, 1122, 10288, 29572, 4, 6052, 1080, 3227, 1122, 18041, 12874, 15425, 6355, 1350, 1080, 3227, 2212, 7026, 1072, 14229, 19283, 29493, 3471, 2146, 1080, 3227, 15623, 1093, 29474, 29491, 29489, 2831, 2320, 15747, 1906, 29600, 1210, 2320, 20757, 29600, 1325, 1072, 20851, 1946, 23842, 29491, 8156, 2685, 1465, 3792, 4449, 23657, 3205, 29493, 1080, 3227, 17137, 6179, 29493, 4515, 2251, 12876, 29493, 1072, 5160, 9028, 1070, 12874, 16019, 1066, 6175, 6413, 18041, 12874, 29491, 2]\n",
            "inputs:\n",
            "<s>[INST] How can `MySQL's `data replication` be configured for disaster recovery, and what are the key considerations for setup?[/INST] Data replication for disaster recovery involves setting up replication between primary and secondary servers, configuring replication modes (e.g., `GTID` or `ROW`), and ensuring data consistency. Key considerations include network reliability, replication lag management, failover strategies, and regular testing of recovery procedures to ensure effective disaster recovery.</s>\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6052, 1080, 3227, 1122, 18041, 12874, 15425, 6355, 1350, 1080, 3227, 2212, 7026, 1072, 14229, 19283, 29493, 3471, 2146, 1080, 3227, 15623, 1093, 29474, 29491, 29489, 2831, 2320, 15747, 1906, 29600, 1210, 2320, 20757, 29600, 1325, 1072, 20851, 1946, 23842, 29491, 8156, 2685, 1465, 3792, 4449, 23657, 3205, 29493, 1080, 3227, 17137, 6179, 29493, 4515, 2251, 12876, 29493, 1072, 5160, 9028, 1070, 12874, 16019, 1066, 6175, 6413, 18041, 12874, 29491, 2]\n",
            "labels:\n",
            "Data replication for disaster recovery involves setting up replication between primary and secondary servers, configuring replication modes (e.g., `GTID` or `ROW`), and ensuring data consistency. Key considerations include network reliability, replication lag management, failover strategies, and regular testing of recovery procedures to ensure effective disaster recovery.</s>\n",
            "[INFO|configuration_utils.py:698] 2025-06-09 08:10:53,267 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/config.json\n",
            "[INFO|configuration_utils.py:770] 2025-06-09 08:10:53,269 >> Model config MistralConfig {\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": null,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32768\n",
            "}\n",
            "\n",
            "[INFO|2025-06-09 08:10:53] llamafactory.model.model_utils.quantization:143 >> Quantizing model to 4 bit with bitsandbytes.\n",
            "[INFO|2025-06-09 08:10:53] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.\n",
            "model.safetensors.index.json: 100% 23.9k/23.9k [00:00<00:00, 86.5MB/s]\n",
            "[INFO|modeling_utils.py:1151] 2025-06-09 08:10:55,630 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/model.safetensors.index.json\n",
            "Fetching 3 files:   0% 0/3 [00:00<?, ?it/s]\n",
            "model-00001-of-00003.safetensors:   0% 0.00/4.95G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   0% 0.00/4.55G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   0% 21.0M/4.95G [00:00<00:27, 180MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   0% 10.5M/4.55G [00:00<00:54, 82.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   0% 21.0M/5.00G [00:00<00:45, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   1% 41.9M/4.95G [00:00<00:26, 182MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   1% 31.5M/4.55G [00:00<00:36, 125MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   1% 41.9M/5.00G [00:00<00:34, 144MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   1% 62.9M/4.95G [00:00<00:32, 153MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   1% 52.4M/4.55G [00:00<00:43, 103MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   2% 83.9M/4.95G [00:00<00:31, 156MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   1% 62.9M/5.00G [00:00<00:44, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   2% 73.4M/4.55G [00:00<00:37, 120MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   2% 105M/4.95G [00:00<00:32, 151MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   2% 83.9M/5.00G [00:00<00:39, 125MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   2% 94.4M/4.55G [00:00<00:31, 142MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   3% 126M/4.95G [00:00<00:30, 161MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   2% 105M/5.00G [00:00<00:35, 137MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   3% 115M/4.55G [00:00<00:33, 132MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   3% 147M/4.95G [00:01<00:40, 120MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   3% 126M/5.00G [00:01<00:58, 83.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   3% 136M/4.55G [00:01<01:13, 60.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   3% 168M/4.95G [00:02<01:49, 43.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   3% 147M/4.55G [00:08<10:02, 7.30MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   3% 147M/5.00G [00:16<19:40, 4.11MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   3% 168M/4.95G [00:17<01:49, 43.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   3% 147M/5.00G [00:27<19:40, 4.11MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   3% 147M/4.55G [00:27<10:02, 7.30MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   4% 178M/4.95G [00:44<1:00:14, 1.32MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   3% 157M/4.55G [00:50<1:11:29, 1.02MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   4% 189M/4.95G [00:50<58:24, 1.36MB/s]  \u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   3% 157M/5.00G [00:50<1:06:15, 1.22MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   4% 168M/4.55G [00:50<54:59, 1.33MB/s]  \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   3% 168M/5.00G [00:50<52:13, 1.54MB/s]  \u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   4% 199M/4.95G [00:51<45:07, 1.75MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   4% 189M/4.55G [00:51<32:54, 2.21MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   4% 189M/5.00G [00:51<32:32, 2.46MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   4% 220M/4.95G [00:51<27:19, 2.89MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   5% 231M/4.95G [00:51<21:24, 3.67MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   4% 210M/5.00G [00:51<21:16, 3.75MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   5% 210M/4.55G [00:51<21:04, 3.43MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   5% 231M/5.00G [00:51<14:19, 5.55MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   5% 220M/4.55G [00:51<16:55, 4.26MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   5% 252M/4.95G [00:51<13:25, 5.83MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   5% 231M/4.55G [00:51<13:11, 5.46MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   5% 262M/4.95G [00:51<10:41, 7.31MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   5% 252M/5.00G [00:51<09:56, 7.96MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   6% 273M/4.95G [00:51<08:22, 9.31MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   6% 252M/4.55G [00:51<08:13, 8.70MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   6% 283M/4.95G [00:51<06:31, 11.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   5% 273M/5.00G [00:51<07:01, 11.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   6% 273M/4.55G [00:52<05:30, 12.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   6% 294M/4.95G [00:52<05:01, 15.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   6% 283M/4.55G [00:52<04:33, 15.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   6% 304M/4.95G [00:52<03:55, 19.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   6% 294M/5.00G [00:52<05:13, 15.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   6% 315M/4.95G [00:52<03:02, 25.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   7% 304M/4.55G [00:52<03:11, 22.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   6% 304M/5.00G [00:52<04:28, 17.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 325M/4.95G [00:52<02:31, 30.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   7% 315M/4.55G [00:52<02:43, 25.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   6% 315M/5.00G [00:52<03:47, 20.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 336M/4.95G [00:52<02:08, 35.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   7% 325M/5.00G [00:52<03:06, 25.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 346M/4.95G [00:52<01:44, 44.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   7% 336M/4.55G [00:52<01:55, 36.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   7% 336M/5.00G [00:52<02:51, 27.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   8% 346M/4.55G [00:54<03:43, 18.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 357M/4.95G [00:54<04:40, 16.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   7% 346M/5.00G [00:54<05:01, 15.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 367M/4.95G [00:55<06:36, 11.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   8% 357M/4.55G [00:55<05:15, 13.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   7% 357M/5.00G [00:55<06:30, 11.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   8% 377M/4.95G [00:56<05:22, 14.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   8% 367M/4.55G [00:56<04:30, 15.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   7% 367M/5.00G [00:56<05:18, 14.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   8% 388M/4.95G [00:56<04:23, 17.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   8% 377M/4.55G [00:56<03:50, 18.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   8% 377M/5.00G [00:56<04:24, 17.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   9% 388M/4.55G [00:56<03:14, 21.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   8% 398M/4.95G [00:56<03:41, 20.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   8% 388M/5.00G [00:56<03:41, 20.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   9% 398M/4.55G [00:57<02:47, 24.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   8% 409M/4.95G [00:57<03:06, 24.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   8% 398M/5.00G [00:57<03:08, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   8% 409M/5.00G [00:57<02:25, 31.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   9% 409M/4.55G [00:57<02:14, 30.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   8% 419M/4.95G [00:57<02:27, 30.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   9% 430M/5.00G [00:57<01:32, 49.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   9% 440M/4.95G [00:57<01:37, 46.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   9% 430M/4.55G [00:57<01:31, 45.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   9% 440M/5.00G [00:57<01:21, 56.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   9% 461M/4.95G [00:57<01:10, 63.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  10% 451M/4.55G [00:57<01:05, 62.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   9% 461M/5.00G [00:57<01:05, 69.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  10% 472M/4.95G [00:57<01:11, 62.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  10% 461M/4.55G [00:57<01:06, 61.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   9% 472M/5.00G [00:57<01:03, 71.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  10% 482M/4.95G [00:57<01:06, 67.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  10% 472M/4.55G [00:57<01:04, 63.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  10% 482M/5.00G [00:57<01:04, 70.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  10% 493M/4.95G [00:57<01:04, 68.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  11% 482M/4.55G [00:57<00:59, 68.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  10% 493M/5.00G [00:58<01:01, 73.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  11% 493M/4.55G [00:58<00:56, 72.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  10% 514M/4.95G [00:58<00:54, 81.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  11% 503M/4.55G [00:58<00:52, 77.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  10% 503M/5.00G [00:58<01:06, 67.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  11% 524M/4.95G [00:58<00:52, 84.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  10% 514M/5.00G [00:58<01:05, 68.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  11% 535M/4.95G [00:58<00:54, 81.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  11% 514M/4.55G [00:58<00:59, 68.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  12% 524M/4.55G [00:58<00:55, 73.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  11% 556M/4.95G [00:58<00:48, 89.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  11% 535M/5.00G [00:58<00:58, 76.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  12% 535M/4.55G [00:58<00:53, 74.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  11% 545M/5.00G [00:58<00:55, 80.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  12% 545M/4.55G [00:58<00:53, 74.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  12% 577M/4.95G [00:58<00:45, 95.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  12% 556M/4.55G [00:58<00:49, 80.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  12% 587M/4.95G [00:58<00:50, 87.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  11% 566M/5.00G [00:59<01:00, 73.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  12% 566M/4.55G [00:59<00:53, 74.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  12% 598M/4.95G [00:59<00:49, 87.2MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  12% 608M/4.95G [00:59<00:50, 85.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  13% 577M/4.55G [00:59<00:58, 68.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  12% 587M/5.00G [00:59<00:55, 79.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  13% 629M/4.95G [00:59<00:44, 97.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  13% 598M/4.55G [00:59<00:47, 83.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  12% 608M/5.00G [00:59<00:53, 81.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  13% 640M/4.95G [00:59<00:47, 90.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  13% 608M/4.55G [00:59<00:47, 83.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  14% 619M/4.55G [00:59<00:49, 80.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  13% 629M/5.00G [00:59<00:50, 85.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  13% 661M/4.95G [00:59<00:46, 92.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  14% 629M/4.55G [00:59<00:50, 78.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  13% 640M/5.00G [00:59<00:54, 80.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  14% 671M/4.95G [00:59<00:56, 75.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  14% 640M/4.55G [01:00<00:55, 70.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  13% 650M/5.00G [01:00<00:56, 76.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  14% 682M/4.95G [01:00<00:53, 79.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  15% 661M/4.55G [01:00<00:48, 79.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  13% 671M/5.00G [01:00<00:53, 80.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  14% 703M/4.95G [01:00<00:51, 82.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  15% 682M/4.55G [01:00<00:39, 98.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  14% 692M/5.00G [01:00<00:44, 95.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  15% 724M/4.95G [01:00<00:43, 97.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  15% 703M/4.55G [01:00<00:36, 106MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  14% 713M/5.00G [01:00<00:46, 92.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  15% 744M/4.95G [01:00<00:48, 87.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  14% 724M/5.00G [01:00<00:52, 81.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  15% 755M/4.95G [01:00<00:51, 81.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  16% 724M/4.55G [01:00<00:48, 78.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  15% 765M/4.95G [01:01<00:55, 75.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  16% 734M/4.55G [01:01<00:49, 76.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  15% 734M/5.00G [01:01<01:04, 66.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  16% 776M/4.95G [01:01<00:54, 76.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  16% 744M/4.55G [01:01<00:49, 77.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  15% 755M/5.00G [01:01<00:50, 83.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  16% 807M/4.95G [01:01<00:41, 100MB/s] \u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  17% 765M/4.55G [01:01<00:44, 85.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  16% 776M/5.00G [01:01<00:47, 89.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  17% 776M/4.55G [01:01<00:45, 82.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  16% 786M/5.00G [01:01<00:49, 85.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  17% 818M/4.95G [01:01<00:48, 85.9MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  17% 828M/4.95G [01:01<00:46, 89.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  18% 797M/4.55G [01:01<00:41, 89.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  17% 839M/4.95G [01:01<00:46, 88.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  16% 807M/5.00G [01:01<00:49, 85.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  16% 818M/5.00G [01:02<00:52, 79.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  18% 807M/4.55G [01:02<00:55, 67.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  17% 860M/4.95G [01:02<00:55, 73.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  17% 828M/5.00G [01:02<01:04, 65.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  17% 860M/4.95G [01:17<00:55, 73.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  17% 828M/5.00G [01:17<01:04, 65.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  18% 818M/4.55G [01:17<00:55, 67.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  18% 828M/4.55G [01:18<18:52, 3.28MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 870M/4.95G [01:18<24:27, 2.78MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  17% 839M/5.00G [01:18<27:57, 2.48MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 870M/4.95G [01:37<24:27, 2.78MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  17% 839M/5.00G [01:37<27:57, 2.48MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  18% 828M/4.55G [01:37<18:52, 3.28MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  18% 839M/4.55G [01:48<53:03, 1.16MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 881M/4.95G [01:50<1:07:49, 1.00MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  17% 849M/5.00G [01:50<1:14:02, 934kB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 891M/4.95G [01:50<50:32, 1.34MB/s]  \u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  19% 849M/4.55G [01:50<42:27, 1.45MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  17% 860M/5.00G [01:50<54:10, 1.27MB/s] \u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 902M/4.95G [01:50<37:08, 1.82MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  19% 860M/4.55G [01:50<32:00, 1.92MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  17% 870M/5.00G [01:50<39:15, 1.75MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 912M/4.95G [01:50<27:02, 2.49MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  19% 870M/4.55G [01:50<23:46, 2.58MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  18% 881M/5.00G [01:50<28:13, 2.43MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  19% 923M/4.95G [01:50<19:31, 3.44MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  19% 881M/4.55G [01:50<17:24, 3.51MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  18% 891M/5.00G [01:50<20:15, 3.38MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  18% 902M/5.00G [01:50<14:30, 4.71MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  19% 944M/4.95G [01:50<11:00, 6.07MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  20% 902M/4.55G [01:50<09:57, 6.10MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  20% 912M/4.55G [01:51<07:42, 7.85MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  19% 954M/4.95G [01:51<08:35, 7.75MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  18% 923M/5.00G [01:51<08:10, 8.32MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  19% 965M/4.95G [01:51<06:33, 10.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  19% 933M/5.00G [01:51<06:21, 10.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 975M/4.95G [01:51<05:01, 13.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  21% 933M/4.55G [01:51<04:54, 12.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  19% 944M/5.00G [01:51<04:56, 13.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 986M/4.95G [01:51<03:49, 17.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  21% 944M/4.55G [01:51<03:56, 15.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  19% 954M/5.00G [01:51<03:47, 17.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  19% 965M/5.00G [01:51<03:00, 22.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  21% 965M/4.55G [01:51<02:40, 22.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 1.01G/4.95G [01:51<02:30, 26.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  20% 986M/5.00G [01:51<01:52, 35.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  21% 1.02G/4.95G [01:51<02:05, 31.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  21% 975M/4.55G [01:51<02:15, 26.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  20% 996M/5.00G [01:51<01:38, 40.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  21% 1.03G/4.95G [01:51<01:45, 37.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  22% 986M/4.55G [01:51<01:53, 31.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  20% 1.01G/5.00G [01:52<01:25, 46.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  22% 996M/4.55G [01:52<01:34, 37.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  20% 1.02G/5.00G [01:52<01:12, 54.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  21% 1.05G/4.95G [01:52<01:15, 51.7MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  21% 1.06G/4.95G [01:52<01:14, 52.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  22% 1.02G/4.55G [01:52<01:15, 46.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  21% 1.04G/5.00G [01:52<01:01, 64.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  22% 1.07G/4.95G [01:52<01:07, 57.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  23% 1.03G/4.55G [01:52<01:08, 51.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  21% 1.05G/5.00G [01:52<01:01, 63.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  22% 1.08G/4.95G [01:52<01:01, 63.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  23% 1.04G/4.55G [01:52<01:04, 54.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  22% 1.09G/4.95G [01:52<00:56, 68.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  21% 1.06G/5.00G [01:52<01:01, 64.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  23% 1.05G/4.55G [01:52<00:57, 60.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  22% 1.10G/4.95G [01:52<00:54, 71.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  21% 1.07G/5.00G [01:52<00:58, 67.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  23% 1.06G/4.55G [01:52<00:54, 64.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  22% 1.11G/4.95G [01:52<00:50, 76.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  22% 1.08G/5.00G [01:52<00:53, 72.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  22% 1.09G/5.00G [01:53<00:49, 78.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  23% 1.12G/4.95G [01:53<00:50, 76.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  24% 1.08G/4.55G [01:53<00:44, 78.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  22% 1.10G/5.00G [01:53<00:48, 79.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  23% 1.13G/4.95G [01:53<00:50, 76.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  24% 1.09G/4.55G [01:53<00:43, 78.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  24% 1.10G/4.55G [01:53<00:43, 78.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  22% 1.12G/5.00G [01:53<00:42, 91.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  23% 1.15G/4.95G [01:53<00:44, 85.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  24% 1.11G/4.55G [01:53<00:41, 83.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  23% 1.13G/5.00G [01:53<00:45, 85.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  24% 1.16G/4.95G [01:53<00:45, 82.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  25% 1.12G/4.55G [01:53<00:40, 83.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  23% 1.14G/5.00G [01:53<00:44, 87.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  24% 1.17G/4.95G [01:53<00:46, 81.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  25% 1.13G/4.55G [01:53<00:40, 85.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  23% 1.15G/5.00G [01:53<00:43, 87.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  24% 1.18G/4.95G [01:53<00:44, 84.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  25% 1.14G/4.55G [01:53<00:37, 89.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  23% 1.16G/5.00G [01:53<00:43, 88.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  25% 1.15G/4.55G [01:54<02:11, 25.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  24% 1.20G/4.95G [01:54<02:24, 25.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  23% 1.17G/5.00G [01:54<02:23, 26.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  26% 1.17G/4.55G [01:55<01:20, 41.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  25% 1.22G/4.95G [01:56<02:52, 21.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  26% 1.18G/4.55G [01:56<02:25, 23.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  24% 1.20G/5.00G [01:56<02:55, 21.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  24% 1.21G/5.00G [01:56<02:22, 26.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  26% 1.20G/4.55G [01:56<01:58, 28.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  25% 1.24G/4.95G [01:56<02:00, 30.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  27% 1.21G/4.55G [01:56<01:35, 35.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  25% 1.23G/5.00G [01:56<01:39, 37.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  25% 1.26G/4.95G [01:56<01:27, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  27% 1.23G/4.55G [01:56<01:03, 52.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  26% 1.28G/4.95G [01:56<01:10, 52.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  25% 1.25G/5.00G [01:56<01:18, 47.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  27% 1.25G/4.55G [01:56<00:52, 62.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  25% 1.26G/5.00G [01:56<01:10, 52.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  28% 1.26G/4.55G [01:56<00:48, 67.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  26% 1.28G/5.00G [01:56<00:54, 68.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  26% 1.30G/4.95G [01:57<01:04, 56.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  28% 1.27G/4.55G [01:57<00:53, 61.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  26% 1.29G/5.00G [01:57<00:54, 68.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  28% 1.28G/4.55G [01:57<00:51, 63.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  27% 1.32G/4.95G [01:57<01:00, 60.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  26% 1.31G/5.00G [01:57<00:46, 80.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  27% 1.33G/4.95G [01:57<00:57, 63.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  29% 1.30G/4.55G [01:57<00:44, 73.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  27% 1.33G/5.00G [01:57<00:42, 85.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  27% 1.34G/4.95G [01:57<00:53, 67.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  29% 1.31G/4.55G [01:57<00:45, 71.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  27% 1.35G/4.95G [01:57<00:50, 70.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  29% 1.32G/4.55G [01:57<00:43, 74.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  27% 1.35G/5.00G [01:57<00:40, 90.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  27% 1.36G/5.00G [01:57<00:39, 91.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  29% 1.33G/4.55G [01:57<00:48, 66.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  28% 1.37G/4.95G [01:57<00:49, 72.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  27% 1.37G/5.00G [01:57<00:39, 91.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  28% 1.38G/5.00G [01:58<00:38, 93.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  30% 1.35G/4.55G [01:58<00:39, 80.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  28% 1.39G/4.95G [01:58<00:43, 82.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  30% 1.36G/4.55G [01:58<00:41, 77.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  28% 1.39G/5.00G [01:58<00:47, 76.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  28% 1.41G/4.95G [01:58<00:44, 79.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  30% 1.37G/4.55G [01:58<00:39, 80.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  28% 1.41G/5.00G [01:58<00:45, 79.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  29% 1.42G/4.95G [01:58<00:45, 76.9MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  29% 1.43G/4.95G [01:58<00:49, 70.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  29% 1.43G/5.00G [01:58<00:43, 82.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  31% 1.39G/4.55G [01:58<00:39, 80.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  31% 1.41G/4.55G [01:58<00:37, 84.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  29% 1.44G/5.00G [01:58<00:42, 84.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  29% 1.45G/4.95G [01:58<00:40, 87.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  29% 1.46G/5.00G [01:58<00:39, 90.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  30% 1.47G/4.95G [01:59<00:41, 83.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  31% 1.43G/4.55G [01:59<00:44, 70.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  29% 1.47G/5.00G [01:59<00:42, 82.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  30% 1.48G/4.95G [01:59<00:43, 80.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  30% 1.48G/5.00G [01:59<00:41, 85.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  32% 1.45G/4.55G [01:59<00:35, 86.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  30% 1.50G/4.95G [01:59<00:38, 89.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  30% 1.50G/5.00G [01:59<00:39, 89.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  32% 1.47G/4.55G [01:59<00:33, 90.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.51G/4.95G [01:59<00:40, 84.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  33% 1.48G/4.55G [01:59<00:33, 91.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  30% 1.51G/5.00G [01:59<00:41, 83.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.52G/4.95G [01:59<00:41, 82.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  33% 1.49G/4.55G [01:59<00:33, 89.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  30% 1.52G/5.00G [01:59<00:42, 82.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.53G/4.95G [01:59<00:43, 78.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  33% 1.50G/4.55G [01:59<00:37, 82.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  31% 1.53G/5.00G [02:17<25:28, 2.27MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  33% 1.51G/4.55G [02:17<21:53, 2.31MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.54G/4.95G [02:17<25:26, 2.23MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  31% 1.56G/5.00G [02:17<12:09, 4.71MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  34% 1.53G/4.55G [02:17<12:47, 3.93MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  32% 1.56G/4.95G [02:17<14:40, 3.85MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  32% 1.58G/5.00G [02:17<08:13, 6.93MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  32% 1.57G/4.95G [02:17<11:20, 4.96MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  34% 1.55G/4.55G [02:17<08:02, 6.21MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  32% 1.59G/4.95G [02:17<06:53, 8.12MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  32% 1.60G/5.00G [02:17<05:41, 9.93MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  35% 1.57G/4.55G [02:17<05:21, 9.26MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 1.61G/4.95G [02:17<04:28, 12.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  33% 1.63G/5.00G [02:17<04:00, 14.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  35% 1.59G/4.55G [02:18<03:38, 13.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 1.64G/4.95G [02:18<03:02, 18.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  33% 1.65G/5.00G [02:18<02:50, 19.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 1.66G/4.95G [02:18<02:28, 22.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  36% 1.61G/4.55G [02:18<02:53, 16.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  33% 1.67G/5.00G [02:18<02:22, 23.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  36% 1.64G/4.55G [02:23<05:17, 9.18MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  34% 1.68G/4.95G [02:23<05:28, 9.97MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  34% 1.69G/5.00G [02:23<05:19, 10.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  36% 1.66G/4.55G [02:23<03:41, 13.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  34% 1.70G/4.95G [02:23<03:50, 14.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  34% 1.71G/5.00G [02:23<03:45, 14.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  37% 1.68G/4.55G [02:23<02:40, 17.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  35% 1.72G/4.95G [02:23<02:46, 19.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  35% 1.73G/5.00G [02:23<02:47, 19.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  37% 1.70G/4.55G [02:23<02:08, 22.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  35% 1.74G/4.95G [02:24<02:20, 22.8MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  35% 1.74G/4.95G [02:37<02:20, 22.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  35% 1.74G/5.00G [02:37<02:46, 19.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  37% 1.70G/4.55G [02:37<02:08, 22.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  35% 1.75G/5.00G [02:40<15:02, 3.60MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  38% 1.71G/4.55G [02:40<15:04, 3.14MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  35% 1.75G/4.95G [02:40<16:51, 3.16MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  38% 1.72G/4.55G [02:40<12:03, 3.91MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  35% 1.76G/5.00G [02:40<12:27, 4.33MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  38% 1.73G/4.55G [02:40<09:25, 4.98MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  35% 1.77G/5.00G [02:40<10:01, 5.36MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  36% 1.77G/4.95G [02:40<11:16, 4.69MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  38% 1.74G/4.55G [02:40<07:12, 6.48MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  36% 1.78G/4.95G [02:40<09:09, 5.76MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  36% 1.78G/5.00G [02:40<07:54, 6.78MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  39% 1.75G/4.55G [02:40<05:28, 8.51MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  36% 1.79G/4.95G [02:40<07:16, 7.23MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  36% 1.79G/5.00G [02:40<06:07, 8.72MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  39% 1.76G/4.55G [02:40<04:07, 11.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  36% 1.80G/4.95G [02:41<05:39, 9.25MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  36% 1.80G/5.00G [02:41<04:41, 11.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  39% 1.77G/4.55G [02:41<03:07, 14.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  37% 1.81G/4.95G [02:41<04:21, 12.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  36% 1.81G/5.00G [02:41<03:34, 14.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  39% 1.79G/4.55G [02:41<01:51, 24.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  37% 1.84G/4.95G [02:41<02:40, 19.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  37% 1.84G/5.00G [02:41<02:10, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  40% 1.82G/4.55G [02:41<01:02, 43.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  37% 1.86G/5.00G [02:41<01:25, 36.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  37% 1.86G/4.95G [02:41<01:57, 26.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  38% 1.88G/5.00G [02:41<01:15, 41.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  41% 1.85G/4.55G [02:41<01:00, 44.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  38% 1.87G/4.95G [02:46<07:08, 7.20MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  38% 1.90G/5.00G [02:47<05:45, 8.98MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  38% 1.88G/4.95G [02:47<06:18, 8.12MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  41% 1.87G/4.55G [02:47<04:38, 9.63MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  38% 1.92G/5.00G [02:47<03:57, 13.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  42% 1.89G/4.55G [02:47<03:15, 13.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  38% 1.90G/4.95G [02:47<03:55, 13.0MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.91G/4.95G [02:48<03:09, 16.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  42% 1.91G/4.55G [02:48<02:22, 18.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  39% 1.94G/5.00G [02:48<02:51, 17.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.92G/4.95G [02:48<02:30, 20.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  42% 1.93G/4.55G [02:48<01:44, 25.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  39% 1.96G/5.00G [02:48<02:04, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.94G/4.95G [02:48<01:37, 30.9MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.95G/4.95G [02:48<01:25, 35.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  40% 1.98G/5.00G [02:48<01:37, 30.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  43% 1.95G/4.55G [02:48<01:22, 31.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  40% 1.96G/4.95G [02:48<01:12, 41.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  43% 1.96G/4.55G [02:48<01:19, 32.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  40% 1.99G/5.00G [02:48<01:34, 31.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  40% 1.97G/4.95G [02:48<01:18, 38.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  43% 1.97G/4.55G [02:58<09:22, 4.58MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  40% 2.00G/5.00G [02:58<11:05, 4.51MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  40% 1.98G/4.95G [02:58<13:40, 3.62MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  44% 2.00G/4.55G [02:58<05:03, 8.37MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  40% 2.02G/5.00G [02:58<07:04, 7.02MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  40% 2.00G/4.95G [02:59<07:52, 6.24MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  45% 2.02G/4.55G [02:59<03:35, 11.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  41% 2.04G/5.00G [02:59<04:44, 10.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  41% 2.02G/4.95G [02:59<04:57, 9.82MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  45% 2.04G/4.55G [02:59<02:33, 16.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  41% 2.07G/5.00G [02:59<03:15, 15.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  41% 2.04G/4.95G [02:59<03:21, 14.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  42% 2.09G/5.00G [02:59<02:31, 19.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  45% 2.07G/4.55G [02:59<02:03, 20.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  42% 2.06G/4.95G [02:59<02:58, 16.2MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  42% 2.08G/4.95G [02:59<01:57, 24.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  42% 2.11G/5.00G [02:59<01:49, 26.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  46% 2.09G/4.55G [03:04<03:59, 10.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  43% 2.13G/5.00G [03:04<04:18, 11.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  42% 2.10G/4.95G [03:04<04:39, 10.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  43% 2.14G/5.00G [03:04<03:35, 13.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  46% 2.11G/4.55G [03:04<02:53, 14.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  43% 2.12G/4.95G [03:04<03:14, 14.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  43% 2.15G/5.00G [03:04<02:57, 16.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  47% 2.12G/4.55G [03:04<02:26, 16.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  43% 2.13G/4.95G [03:04<02:42, 17.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  43% 2.17G/5.00G [03:04<01:56, 24.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  47% 2.14G/4.55G [03:04<01:41, 23.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  43% 2.14G/4.95G [03:04<02:16, 20.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  44% 2.19G/5.00G [03:04<01:24, 33.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  48% 2.16G/4.55G [03:04<01:14, 31.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  43% 2.15G/4.95G [03:04<01:56, 24.0MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  44% 2.16G/4.95G [03:05<02:10, 21.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  48% 2.18G/4.55G [03:10<04:14, 9.31MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  44% 2.21G/5.00G [03:10<05:11, 8.94MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  44% 2.17G/4.95G [03:10<07:30, 6.17MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  49% 2.21G/4.55G [03:10<02:34, 15.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  45% 2.23G/5.00G [03:10<03:37, 12.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  44% 2.19G/4.95G [03:10<04:25, 10.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  49% 2.23G/4.55G [03:10<01:57, 19.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  45% 2.25G/5.00G [03:10<02:33, 17.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 2.21G/4.95G [03:10<02:50, 16.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  49% 2.24G/4.55G [03:10<01:42, 22.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 2.22G/4.95G [03:11<02:22, 19.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  46% 2.28G/5.00G [03:11<01:55, 23.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 2.23G/4.95G [03:11<01:56, 23.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  50% 2.25G/4.55G [03:11<01:33, 24.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  46% 2.29G/5.00G [03:11<01:40, 27.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  46% 2.25G/4.95G [03:11<01:18, 34.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  50% 2.28G/4.55G [03:11<01:07, 33.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  46% 2.31G/5.00G [03:11<01:15, 35.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  46% 2.26G/4.95G [03:11<01:08, 39.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  50% 2.29G/4.55G [03:11<00:59, 38.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  46% 2.32G/5.00G [03:11<01:08, 38.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  51% 2.30G/4.55G [03:11<00:51, 43.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  47% 2.33G/5.00G [03:11<01:00, 44.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  46% 2.29G/4.95G [03:11<00:53, 49.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  51% 2.31G/4.55G [03:11<00:44, 50.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  47% 2.34G/5.00G [03:11<00:56, 47.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  47% 2.31G/4.95G [03:12<00:43, 61.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  51% 2.32G/4.55G [03:12<00:43, 51.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  47% 2.32G/4.95G [03:12<00:41, 62.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  51% 2.34G/4.55G [03:12<00:32, 67.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  47% 2.36G/5.00G [03:12<00:45, 58.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  47% 2.34G/4.95G [03:12<00:37, 69.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  47% 2.37G/5.00G [03:12<00:46, 56.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  52% 2.35G/4.55G [03:12<00:36, 60.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  48% 2.36G/4.95G [03:12<00:29, 89.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  48% 2.38G/5.00G [03:12<00:41, 62.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  52% 2.37G/4.55G [03:12<00:31, 69.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  48% 2.39G/5.00G [03:12<00:40, 64.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  48% 2.38G/4.95G [03:12<00:30, 84.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  53% 2.39G/4.55G [03:12<00:28, 76.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  48% 2.41G/5.00G [03:12<00:35, 72.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  48% 2.39G/4.95G [03:12<00:31, 81.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  53% 2.40G/4.55G [03:12<00:27, 79.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  48% 2.42G/5.00G [03:13<00:34, 75.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.40G/4.95G [03:13<00:30, 84.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  53% 2.41G/4.55G [03:13<00:26, 81.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  49% 2.43G/5.00G [03:13<00:34, 74.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.41G/4.95G [03:13<00:31, 81.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  53% 2.42G/4.55G [03:13<00:29, 70.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.42G/4.95G [03:13<00:32, 78.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  49% 2.44G/5.00G [03:13<00:36, 70.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.43G/4.95G [03:13<00:30, 82.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  54% 2.44G/4.55G [03:13<00:23, 88.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  49% 2.46G/5.00G [03:13<00:30, 82.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.44G/4.95G [03:13<00:29, 86.1MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 2.45G/4.95G [03:13<00:27, 89.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  54% 2.47G/4.55G [03:13<00:21, 96.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  50% 2.49G/5.00G [03:13<00:32, 77.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 2.46G/4.95G [03:13<00:34, 71.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  55% 2.49G/4.55G [03:13<00:22, 90.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  50% 2.50G/5.00G [03:13<00:33, 75.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 2.47G/4.95G [03:14<00:33, 73.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  55% 2.50G/4.55G [03:14<00:28, 72.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  50% 2.51G/5.00G [03:14<00:42, 59.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 2.49G/4.95G [03:19<07:07, 5.77MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  50% 2.52G/5.00G [03:20<06:38, 6.22MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 2.50G/4.95G [03:20<05:44, 7.13MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  51% 2.53G/4.95G [03:20<02:34, 15.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  55% 2.51G/4.55G [03:20<05:10, 6.57MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  51% 2.55G/5.00G [03:20<03:22, 12.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  56% 2.54G/4.55G [03:20<02:40, 12.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  51% 2.55G/4.95G [03:20<01:52, 21.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  51% 2.57G/5.00G [03:20<02:20, 17.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  56% 2.55G/4.55G [03:20<02:13, 15.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  52% 2.57G/4.95G [03:21<01:21, 29.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  57% 2.57G/4.55G [03:21<01:30, 21.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  52% 2.59G/5.00G [03:21<01:41, 23.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  52% 2.60G/5.00G [03:21<01:27, 27.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  52% 2.59G/4.95G [03:21<01:02, 37.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  57% 2.59G/4.55G [03:21<01:07, 29.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  52% 2.61G/5.00G [03:21<01:16, 31.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  57% 2.60G/4.55G [03:21<00:59, 32.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  52% 2.62G/5.00G [03:21<01:06, 36.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.61G/4.95G [03:21<00:54, 43.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  57% 2.61G/4.55G [03:21<00:54, 35.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  53% 2.63G/5.00G [03:21<01:03, 37.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.62G/4.95G [03:22<01:07, 34.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  58% 2.62G/4.55G [03:26<04:27, 7.19MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  53% 2.64G/5.00G [03:27<06:05, 6.45MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.63G/4.95G [03:30<07:34, 5.09MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  53% 2.64G/5.00G [03:37<06:05, 6.45MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  58% 2.62G/4.55G [03:37<04:27, 7.19MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  58% 2.63G/4.55G [03:38<11:51, 2.69MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.63G/4.95G [03:47<07:34, 5.09MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  58% 2.63G/4.55G [03:48<11:51, 2.69MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  53% 2.65G/5.00G [03:48<25:48, 1.52MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.64G/4.95G [04:05<34:50, 1.10MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  58% 2.64G/4.55G [04:05<30:48, 1.03MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  54% 2.67G/4.95G [04:05<17:27, 2.17MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  53% 2.66G/5.00G [04:05<36:41, 1.06MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  54% 2.69G/4.95G [04:05<11:49, 3.18MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  59% 2.66G/4.55G [04:05<17:28, 1.80MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  53% 2.67G/5.00G [04:05<26:12, 1.48MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  55% 2.72G/4.95G [04:06<08:09, 4.56MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  59% 2.68G/4.55G [04:06<10:48, 2.87MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  54% 2.68G/5.00G [04:06<18:44, 2.06MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  59% 2.69G/4.55G [04:06<08:33, 3.61MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  54% 2.69G/5.00G [04:06<13:22, 2.87MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  55% 2.74G/4.95G [04:06<05:41, 6.47MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  60% 2.72G/4.55G [04:06<05:21, 5.70MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  54% 2.71G/5.00G [04:06<09:36, 3.98MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  60% 2.74G/4.55G [04:06<03:32, 8.52MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  56% 2.76G/4.95G [04:06<04:08, 8.84MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  55% 2.73G/5.00G [04:06<05:21, 7.08MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  61% 2.76G/4.55G [04:06<02:23, 12.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  55% 2.75G/5.00G [04:06<03:20, 11.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  56% 2.78G/4.95G [04:06<02:57, 12.2MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  56% 2.79G/4.95G [04:07<02:29, 14.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  55% 2.77G/5.00G [04:07<02:12, 16.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  61% 2.78G/4.55G [04:07<01:45, 16.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.80G/4.95G [04:07<02:04, 17.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  56% 2.78G/5.00G [04:07<01:50, 20.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  56% 2.79G/5.00G [04:07<01:33, 23.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.81G/4.95G [04:07<01:45, 20.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  62% 2.80G/4.55G [04:07<01:18, 22.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  56% 2.81G/5.00G [04:07<01:03, 34.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  62% 2.82G/4.55G [04:07<00:59, 29.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  56% 2.82G/5.00G [04:07<00:54, 40.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.83G/4.95G [04:07<01:13, 28.7MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.84G/4.95G [04:07<01:02, 33.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  62% 2.83G/4.55G [04:07<00:52, 32.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  57% 2.83G/5.00G [04:07<00:50, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  58% 2.86G/4.95G [04:07<00:44, 46.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  63% 2.85G/4.55G [04:08<00:41, 40.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  57% 2.85G/5.00G [04:08<00:40, 53.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  57% 2.87G/5.00G [04:08<00:30, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  58% 2.88G/4.95G [04:08<00:39, 52.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  63% 2.86G/4.55G [04:08<00:39, 42.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  63% 2.87G/4.55G [04:08<00:36, 46.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  58% 2.89G/5.00G [04:08<00:29, 71.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  59% 2.90G/4.95G [04:08<00:34, 59.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  63% 2.88G/4.55G [04:08<00:31, 52.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  58% 2.90G/5.00G [04:09<00:54, 38.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  59% 2.92G/4.95G [04:09<01:13, 27.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  64% 2.89G/4.55G [04:14<04:02, 6.81MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  58% 2.92G/5.00G [04:14<04:10, 8.31MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  59% 2.93G/4.95G [04:14<04:00, 8.43MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  64% 2.90G/4.55G [04:14<03:07, 8.75MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  59% 2.93G/5.00G [04:14<03:21, 10.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  59% 2.94G/4.95G [04:14<03:12, 10.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  59% 2.94G/5.00G [04:14<02:36, 13.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 2.95G/4.95G [04:14<02:30, 13.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  64% 2.93G/4.55G [04:14<01:53, 14.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  59% 2.96G/5.00G [04:14<01:37, 20.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 2.97G/4.95G [04:14<01:36, 20.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  65% 2.95G/4.55G [04:14<01:16, 20.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  60% 2.98G/5.00G [04:14<01:07, 30.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 2.99G/4.95G [04:14<01:08, 28.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  60% 2.99G/5.00G [04:15<00:59, 33.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  65% 2.97G/4.55G [04:15<00:55, 28.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  60% 3.00G/5.00G [04:15<00:50, 40.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  65% 2.98G/4.55G [04:15<00:47, 32.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  61% 3.01G/4.95G [04:15<00:49, 39.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  60% 3.02G/5.00G [04:15<00:36, 54.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  66% 3.00G/4.55G [04:15<00:33, 45.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  61% 3.03G/4.95G [04:15<00:37, 50.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  61% 3.04G/5.00G [04:15<00:29, 66.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  61% 3.04G/4.95G [04:15<00:35, 53.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  66% 3.02G/4.55G [04:15<00:27, 55.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  61% 3.06G/5.00G [04:15<00:24, 78.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  62% 3.06G/4.95G [04:15<00:28, 65.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  67% 3.04G/4.55G [04:15<00:22, 66.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  62% 3.08G/5.00G [04:15<00:20, 94.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  67% 3.06G/4.55G [04:15<00:17, 84.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  62% 3.07G/4.95G [04:15<00:32, 58.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  62% 3.10G/5.00G [04:16<00:21, 89.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  68% 3.09G/4.55G [04:16<00:17, 84.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 3.10G/4.95G [04:16<00:24, 75.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  62% 3.12G/5.00G [04:16<00:22, 83.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 3.11G/4.95G [04:16<00:25, 71.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  63% 3.14G/5.00G [04:16<00:24, 75.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 3.12G/4.95G [04:16<00:29, 62.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  68% 3.11G/4.55G [04:16<00:21, 67.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  63% 3.15G/5.00G [04:21<03:15, 9.50MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 3.14G/4.95G [04:21<03:50, 7.88MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  69% 3.12G/4.55G [04:21<02:16, 10.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  63% 3.16G/5.00G [04:21<02:55, 10.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  64% 3.17G/4.95G [04:22<01:58, 15.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  64% 3.18G/5.00G [04:22<01:48, 16.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  69% 3.15G/4.55G [04:22<01:34, 14.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  64% 3.18G/4.95G [04:22<01:40, 17.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  64% 3.20G/5.00G [04:22<01:14, 24.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  70% 3.17G/4.55G [04:22<01:07, 20.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  64% 3.19G/4.95G [04:22<01:22, 21.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  64% 3.21G/5.00G [04:22<01:03, 28.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  70% 3.19G/4.55G [04:22<00:48, 27.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 3.20G/4.95G [04:22<01:07, 26.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  65% 3.23G/5.00G [04:28<03:36, 8.19MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  65% 3.26G/5.00G [04:28<02:02, 14.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 3.21G/4.95G [04:28<04:52, 5.96MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  71% 3.21G/4.55G [04:28<02:27, 9.04MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  66% 3.28G/5.00G [04:28<01:27, 19.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 3.23G/4.95G [04:28<02:54, 9.87MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  71% 3.23G/4.55G [04:28<01:45, 12.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  66% 3.30G/5.00G [04:28<01:05, 25.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 3.24G/4.95G [04:28<02:17, 12.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  71% 3.25G/4.55G [04:28<01:15, 17.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  66% 3.25G/4.95G [04:28<01:47, 15.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  66% 3.32G/5.00G [04:28<00:50, 33.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  72% 3.27G/4.55G [04:28<00:54, 23.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  66% 3.27G/4.95G [04:28<01:07, 24.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  67% 3.34G/5.00G [04:28<00:38, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  66% 3.28G/4.95G [04:28<00:55, 29.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  72% 3.29G/4.55G [04:29<00:42, 29.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.29G/4.95G [04:29<00:48, 34.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  67% 3.37G/5.00G [04:29<00:33, 48.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  73% 3.30G/4.55G [04:29<00:38, 32.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.30G/4.95G [04:29<00:41, 39.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  73% 3.31G/4.55G [04:29<00:37, 33.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.31G/4.95G [04:29<00:43, 37.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  68% 3.39G/5.00G [04:32<01:39, 16.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  73% 3.32G/4.55G [04:32<01:46, 11.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.32G/4.95G [04:32<02:46, 9.74MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  68% 3.40G/5.00G [04:38<04:13, 6.33MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.32G/4.95G [04:47<02:46, 9.74MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  73% 3.32G/4.55G [04:47<01:46, 11.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  73% 3.33G/4.55G [04:49<09:02, 2.23MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.33G/4.95G [04:57<20:01, 1.34MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  68% 3.40G/5.00G [04:57<04:13, 6.33MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.33G/4.95G [05:07<20:01, 1.34MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  73% 3.33G/4.55G [05:07<09:02, 2.23MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  68% 3.41G/5.00G [05:13<20:45, 1.28MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  69% 3.44G/5.00G [05:13<10:59, 2.37MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  74% 3.34G/4.55G [05:13<18:35, 1.08MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  68% 3.34G/4.95G [05:13<25:53, 1.03MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  69% 3.46G/5.00G [05:13<07:34, 3.39MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  68% 3.37G/4.95G [05:13<14:03, 1.88MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  74% 3.37G/4.55G [05:13<10:37, 1.85MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  70% 3.48G/5.00G [05:13<05:15, 4.81MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  68% 3.39G/4.95G [05:13<08:32, 3.05MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  74% 3.38G/4.55G [05:13<08:09, 2.39MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 3.41G/4.95G [05:13<05:27, 4.70MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  74% 3.39G/4.55G [05:13<06:07, 3.15MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  70% 3.50G/5.00G [05:13<03:43, 6.70MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 3.42G/4.95G [05:13<04:22, 5.84MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  70% 3.52G/5.00G [05:15<03:02, 8.09MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 3.43G/4.95G [05:15<04:10, 6.06MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  75% 3.41G/4.55G [05:15<04:09, 4.57MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  75% 3.42G/4.55G [05:19<04:41, 4.00MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 3.44G/4.95G [05:19<05:25, 4.64MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  71% 3.53G/5.00G [05:19<04:11, 5.83MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  76% 3.45G/4.55G [05:19<02:20, 7.82MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  71% 3.55G/5.00G [05:19<02:47, 8.63MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  76% 3.47G/4.55G [05:19<01:35, 11.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  70% 3.46G/4.95G [05:19<03:14, 7.66MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  72% 3.58G/5.00G [05:19<01:55, 12.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  71% 3.49G/4.95G [05:19<01:45, 13.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  77% 3.49G/4.55G [05:19<01:08, 15.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  72% 3.59G/5.00G [05:19<01:39, 14.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  71% 3.51G/4.95G [05:19<01:15, 19.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  77% 3.51G/4.55G [05:19<00:49, 21.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  72% 3.60G/5.00G [05:19<01:20, 17.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  71% 3.52G/4.95G [05:20<01:04, 22.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  72% 3.61G/5.00G [05:20<01:14, 18.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  71% 3.53G/4.95G [05:21<01:31, 15.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  72% 3.62G/5.00G [05:23<02:49, 8.16MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  78% 3.53G/4.55G [05:25<01:48, 9.31MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.54G/4.95G [05:26<03:38, 6.42MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  73% 3.63G/5.00G [05:31<06:39, 3.44MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  78% 3.54G/4.55G [05:33<03:55, 4.25MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.55G/4.95G [05:37<08:39, 2.68MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.55G/4.95G [05:47<08:39, 2.68MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  73% 3.63G/5.00G [05:47<06:39, 3.44MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  78% 3.54G/4.55G [05:47<03:55, 4.25MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  73% 3.64G/5.00G [05:55<18:29, 1.23MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  78% 3.55G/4.55G [05:55<10:00, 1.65MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  78% 3.57G/4.55G [05:55<07:43, 2.12MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.57G/4.95G [05:55<16:36, 1.39MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  73% 3.66G/5.00G [05:55<10:21, 2.16MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.59G/4.95G [05:55<09:27, 2.40MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  79% 3.58G/4.55G [05:55<05:51, 2.76MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  73% 3.67G/5.00G [05:55<07:55, 2.79MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  73% 3.60G/4.95G [05:55<07:18, 3.09MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  79% 3.59G/4.55G [05:55<04:22, 3.66MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  74% 3.68G/5.00G [05:55<05:58, 3.68MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  73% 3.61G/4.95G [05:55<05:32, 4.03MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  79% 3.60G/4.55G [05:55<03:14, 4.89MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  74% 3.69G/5.00G [05:55<04:27, 4.89MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  73% 3.62G/4.95G [05:56<04:09, 5.33MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  79% 3.61G/4.55G [05:56<02:23, 6.53MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  74% 3.70G/5.00G [05:56<03:17, 6.56MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  73% 3.63G/4.95G [05:56<03:06, 7.08MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  80% 3.62G/4.55G [05:56<01:45, 8.81MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  74% 3.72G/5.00G [05:56<01:52, 11.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  74% 3.64G/4.95G [05:56<02:17, 9.51MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  80% 3.63G/4.55G [05:56<01:17, 11.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  75% 3.74G/5.00G [05:56<01:11, 17.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  80% 3.64G/4.55G [05:56<00:57, 15.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  74% 3.66G/4.95G [05:56<01:20, 16.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  75% 3.75G/5.00G [05:56<00:59, 21.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  80% 3.65G/4.55G [05:56<00:42, 20.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  74% 3.67G/4.95G [05:56<01:03, 20.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  76% 3.77G/5.00G [05:56<00:39, 30.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  74% 3.68G/4.95G [05:56<00:50, 25.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  81% 3.67G/4.55G [05:56<00:27, 32.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  75% 3.69G/4.95G [05:56<00:41, 30.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  76% 3.79G/5.00G [05:56<00:35, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  81% 3.68G/4.55G [05:56<00:23, 37.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  75% 3.70G/4.95G [05:56<00:33, 37.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  81% 3.69G/4.55G [05:57<00:19, 44.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  76% 3.80G/5.00G [05:57<00:31, 38.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  75% 3.72G/4.95G [05:57<00:24, 50.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  76% 3.81G/5.00G [05:57<00:27, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  82% 3.71G/4.55G [05:57<00:14, 56.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  76% 3.82G/5.00G [05:57<00:23, 50.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  75% 3.73G/4.95G [05:57<00:21, 56.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  77% 3.83G/5.00G [05:57<00:21, 54.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  82% 3.73G/4.55G [05:57<00:12, 66.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  76% 3.75G/4.95G [05:57<00:18, 64.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  77% 3.84G/5.00G [05:57<00:20, 57.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  82% 3.74G/4.55G [05:57<00:11, 68.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  83% 3.75G/4.55G [05:57<00:11, 71.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  76% 3.77G/4.95G [05:57<00:16, 71.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  77% 3.86G/5.00G [05:57<00:16, 71.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  83% 3.76G/4.55G [05:57<00:10, 76.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  77% 3.87G/5.00G [05:57<00:15, 73.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  83% 3.77G/4.55G [05:58<00:09, 78.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  77% 3.80G/4.95G [05:58<00:15, 76.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  78% 3.88G/5.00G [05:58<00:14, 76.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  83% 3.79G/4.55G [05:58<00:09, 82.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  78% 3.89G/5.00G [05:58<00:15, 73.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  83% 3.80G/4.55G [05:58<00:09, 78.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  77% 3.82G/4.95G [05:58<00:13, 82.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  78% 3.90G/5.00G [05:58<00:17, 62.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  84% 3.81G/4.55G [05:58<00:11, 63.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  77% 3.83G/4.95G [05:58<00:16, 69.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  84% 3.82G/4.55G [05:58<00:11, 61.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  78% 3.84G/4.95G [05:58<00:17, 63.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  78% 3.92G/5.00G [05:58<00:16, 63.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  84% 3.83G/4.55G [05:58<00:11, 65.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  78% 3.85G/4.95G [05:58<00:16, 66.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  79% 3.93G/5.00G [05:58<00:15, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  79% 3.94G/5.00G [05:59<00:13, 75.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  85% 3.85G/4.55G [05:59<00:08, 80.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  78% 3.87G/4.95G [05:59<00:13, 81.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  79% 3.95G/5.00G [05:59<00:15, 69.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  85% 3.86G/4.55G [05:59<00:09, 70.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  78% 3.88G/4.95G [05:59<00:15, 68.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  79% 3.96G/5.00G [05:59<00:14, 70.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  79% 3.89G/4.95G [05:59<00:14, 72.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  85% 3.88G/4.55G [05:59<00:08, 80.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  79% 3.97G/5.00G [05:59<00:13, 75.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  79% 3.90G/4.95G [05:59<00:13, 78.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  86% 3.89G/4.55G [05:59<00:08, 81.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  80% 3.98G/5.00G [05:59<00:12, 79.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  79% 3.92G/4.95G [05:59<00:11, 92.3MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  86% 3.91G/4.55G [05:59<00:06, 94.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  80% 4.00G/5.00G [05:59<00:14, 71.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  86% 3.92G/4.55G [05:59<00:06, 91.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  80% 4.01G/5.00G [05:59<00:13, 74.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 3.94G/4.95G [05:59<00:11, 91.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  86% 3.93G/4.55G [05:59<00:06, 93.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 3.95G/4.95G [06:00<00:10, 92.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  80% 4.02G/5.00G [06:00<00:13, 72.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  87% 3.94G/4.55G [06:00<00:06, 93.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 3.96G/4.95G [06:00<00:10, 95.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  81% 4.03G/5.00G [06:00<00:12, 79.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  87% 3.95G/4.55G [06:00<00:06, 91.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 3.97G/4.95G [06:00<00:10, 89.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  87% 3.96G/4.55G [06:00<00:06, 89.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  81% 4.05G/5.00G [06:00<00:11, 86.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  81% 3.98G/4.95G [06:00<00:10, 90.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  81% 4.06G/5.00G [06:00<00:10, 87.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  88% 3.98G/4.55G [06:00<00:05, 95.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  81% 4.01G/4.95G [06:00<00:10, 92.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  88% 4.00G/4.55G [06:00<00:05, 96.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  82% 4.08G/5.00G [06:00<00:09, 93.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  81% 4.02G/4.95G [06:00<00:10, 92.9MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  88% 4.02G/4.55G [06:00<00:05, 104MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  82% 4.10G/5.00G [06:00<00:08, 103MB/s] \u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  82% 4.04G/4.95G [06:00<00:08, 107MB/s] \u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  89% 4.04G/4.55G [06:00<00:04, 112MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  82% 4.06G/4.95G [06:01<00:07, 117MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  82% 4.12G/5.00G [06:01<00:08, 107MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  89% 4.06G/4.55G [06:01<00:05, 93.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  82% 4.08G/4.95G [06:01<00:09, 93.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  83% 4.14G/5.00G [06:01<00:09, 90.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  89% 4.07G/4.55G [06:01<00:05, 90.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  83% 4.15G/5.00G [06:01<00:09, 89.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.09G/4.95G [06:01<00:09, 89.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  90% 4.08G/4.55G [06:01<00:05, 81.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  83% 4.16G/5.00G [06:01<00:10, 81.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.10G/4.95G [06:01<00:10, 80.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  90% 4.09G/4.55G [06:06<00:59, 7.65MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  83% 4.17G/5.00G [06:11<03:07, 4.41MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.10G/4.95G [06:17<00:10, 80.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  90% 4.09G/4.55G [06:17<00:59, 7.65MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  83% 4.17G/5.00G [06:27<03:07, 4.41MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.11G/4.95G [06:37<11:22, 1.23MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  90% 4.10G/4.55G [06:38<06:20, 1.17MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  84% 4.18G/5.00G [06:38<11:10, 1.22MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.12G/4.95G [06:38<08:58, 1.54MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  90% 4.10G/4.55G [06:48<06:20, 1.17MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  90% 4.11G/4.55G [06:54<07:32, 965kB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.12G/4.95G [06:57<08:58, 1.54MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  84% 4.18G/5.00G [06:57<11:10, 1.22MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  90% 4.11G/4.55G [07:07<07:32, 965kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  84% 4.19G/5.00G [07:08<18:05, 742kB/s] \u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.13G/4.95G [07:08<16:39, 819kB/s] \u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  91% 4.12G/4.55G [07:08<07:56, 895kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  84% 4.22G/5.00G [07:08<10:04, 1.30MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  84% 4.15G/4.95G [07:08<09:14, 1.44MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  91% 4.14G/4.55G [07:08<04:14, 1.59MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  85% 4.24G/5.00G [07:08<06:07, 2.08MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  91% 4.15G/4.55G [07:08<03:09, 2.08MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  84% 4.17G/4.95G [07:08<05:36, 2.31MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  92% 4.16G/4.55G [07:08<02:20, 2.74MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 4.18G/4.95G [07:08<04:25, 2.88MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  85% 4.25G/5.00G [07:08<04:49, 2.60MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  92% 4.17G/4.55G [07:08<01:41, 3.69MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 4.20G/4.95G [07:08<02:43, 4.57MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  85% 4.27G/5.00G [07:08<02:58, 4.10MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  92% 4.18G/4.55G [07:09<01:12, 4.98MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 4.22G/4.95G [07:09<02:08, 5.71MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  86% 4.28G/5.00G [07:09<02:22, 5.08MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 4.23G/4.95G [07:09<01:47, 6.71MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  92% 4.20G/4.55G [07:10<00:46, 7.38MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  86% 4.29G/5.00G [07:10<02:06, 5.61MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  86% 4.24G/4.95G [07:13<02:25, 4.91MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  93% 4.22G/4.55G [07:13<01:03, 5.23MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  86% 4.30G/5.00G [07:13<02:32, 4.60MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  86% 4.25G/4.95G [07:13<01:53, 6.22MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  86% 4.32G/5.00G [07:14<01:27, 7.76MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  93% 4.24G/4.55G [07:14<00:36, 8.63MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  86% 4.27G/4.95G [07:14<01:04, 10.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  94% 4.26G/4.55G [07:14<00:22, 13.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  87% 4.34G/5.00G [07:14<00:55, 11.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  94% 4.27G/4.55G [07:14<00:17, 16.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  87% 4.35G/5.00G [07:14<00:44, 14.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 4.29G/4.95G [07:14<00:41, 15.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  87% 4.36G/5.00G [07:14<00:35, 18.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 4.30G/4.95G [07:14<00:33, 19.2MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  94% 4.29G/4.55G [07:14<00:10, 23.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  88% 4.38G/5.00G [07:15<00:26, 23.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 4.32G/4.95G [07:15<00:29, 21.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  95% 4.31G/4.55G [07:19<00:26, 9.01MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  95% 4.32G/4.55G [07:20<00:22, 10.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  96% 4.37G/4.55G [07:20<00:07, 23.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 4.33G/4.95G [07:20<01:25, 7.23MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  97% 4.40G/4.55G [07:20<00:04, 34.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  88% 4.39G/5.00G [07:20<01:29, 6.81MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  88% 4.34G/4.95G [07:20<01:06, 9.15MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  88% 4.40G/5.00G [07:20<01:08, 8.64MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  88% 4.35G/4.95G [07:20<00:51, 11.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  97% 4.42G/4.55G [07:20<00:03, 39.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  89% 4.42G/5.00G [07:20<00:41, 13.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  88% 4.36G/4.95G [07:20<00:39, 15.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  89% 4.44G/5.00G [07:20<00:33, 17.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  98% 4.45G/4.55G [07:20<00:02, 45.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 4.38G/4.95G [07:20<00:23, 23.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  89% 4.45G/5.00G [07:20<00:25, 21.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  98% 4.47G/4.55G [07:21<00:01, 52.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  89% 4.47G/5.00G [07:21<00:21, 25.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 4.40G/4.95G [07:21<00:22, 24.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  90% 4.48G/5.00G [07:23<00:38, 13.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 4.41G/4.95G [07:26<01:03, 8.42MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  90% 4.49G/5.00G [07:26<01:00, 8.40MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 4.42G/4.95G [07:26<00:50, 10.3MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  90% 4.46G/4.95G [07:26<00:24, 19.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  90% 4.52G/5.00G [07:26<00:29, 16.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  99% 4.49G/4.55G [07:26<00:04, 11.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  90% 4.48G/4.95G [07:26<00:17, 27.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  91% 4.54G/5.00G [07:26<00:19, 23.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  99% 4.51G/4.55G [07:26<00:02, 16.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  91% 4.50G/4.95G [07:27<00:17, 26.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  91% 4.56G/5.00G [07:27<00:19, 22.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors: 100% 4.53G/4.55G [07:27<00:00, 17.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  91% 4.51G/4.95G [07:32<00:52, 8.46MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors: 100% 4.54G/4.55G [07:32<00:00, 7.87MB/s]\u001b[A\u001b[A\n",
            "model-00003-of-00003.safetensors: 100% 4.55G/4.55G [07:32<00:00, 10.0MB/s]\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  91% 4.57G/5.00G [07:32<00:53, 7.99MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  92% 4.55G/4.95G [07:32<00:21, 18.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  92% 4.59G/5.00G [07:32<00:34, 11.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  92% 4.57G/4.95G [07:32<00:14, 25.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  92% 4.60G/5.00G [07:32<00:27, 14.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  93% 4.59G/4.95G [07:32<00:10, 33.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  92% 4.62G/5.00G [07:33<00:18, 20.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  93% 4.61G/4.95G [07:33<00:07, 43.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  93% 4.65G/5.00G [07:33<00:12, 29.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  94% 4.65G/4.95G [07:33<00:04, 63.4MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  94% 4.67G/4.95G [07:33<00:03, 72.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  94% 4.68G/5.00G [07:33<00:07, 44.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  94% 4.70G/5.00G [07:33<00:05, 56.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  95% 4.69G/4.95G [07:33<00:03, 76.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  94% 4.72G/5.00G [07:34<00:08, 31.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  95% 4.71G/4.95G [07:35<00:07, 33.2MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  95% 4.72G/4.95G [07:38<00:18, 12.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  95% 4.73G/5.00G [07:38<00:23, 11.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  96% 4.76G/4.95G [07:38<00:07, 23.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  95% 4.75G/5.00G [07:38<00:15, 16.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  97% 4.79G/4.95G [07:38<00:04, 34.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  95% 4.77G/5.00G [07:38<00:09, 23.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  97% 4.81G/4.95G [07:39<00:03, 41.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  96% 4.79G/5.00G [07:39<00:06, 31.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  98% 4.83G/4.95G [07:39<00:02, 52.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  96% 4.81G/5.00G [07:39<00:04, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  98% 4.85G/4.95G [07:39<00:01, 65.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  97% 4.83G/5.00G [07:39<00:03, 52.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  99% 4.88G/4.95G [07:39<00:00, 76.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  97% 4.85G/5.00G [07:39<00:02, 62.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  99% 4.90G/4.95G [07:39<00:00, 83.9MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  99% 4.92G/4.95G [07:40<00:00, 60.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  98% 4.88G/5.00G [07:40<00:02, 47.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  98% 4.89G/5.00G [07:41<00:03, 29.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  98% 4.90G/5.00G [07:44<00:09, 10.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  99% 4.93G/5.00G [07:44<00:03, 18.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors: 100% 4.94G/4.95G [07:44<00:00, 12.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  99% 4.96G/5.00G [07:44<00:01, 29.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors: 100% 4.95G/4.95G [07:44<00:00, 10.6MB/s]\n",
            "Fetching 3 files:  33% 1/3 [07:45<15:30, 465.27s/it]\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors: 100% 5.00G/5.00G [07:45<00:00, 10.7MB/s]\n",
            "Fetching 3 files: 100% 3/3 [07:45<00:00, 155.17s/it]\n",
            "[INFO|modeling_utils.py:2241] 2025-06-09 08:18:41,543 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:1135] 2025-06-09 08:18:41,546 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"use_cache\": false\n",
            "}\n",
            "\n",
            "Loading checkpoint shards: 100% 3/3 [01:35<00:00, 31.75s/it]\n",
            "[INFO|modeling_utils.py:5131] 2025-06-09 08:20:17,178 >> All model checkpoint weights were used when initializing MistralForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:5139] 2025-06-09 08:20:17,178 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at mistralai/Mistral-7B-Instruct-v0.3.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n",
            "generation_config.json: 100% 116/116 [00:00<00:00, 739kB/s]\n",
            "[INFO|configuration_utils.py:1090] 2025-06-09 08:20:17,700 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/generation_config.json\n",
            "[INFO|configuration_utils.py:1135] 2025-06-09 08:20:17,700 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2\n",
            "}\n",
            "\n",
            "[INFO|2025-06-09 08:20:18] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.\n",
            "[INFO|2025-06-09 08:20:18] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
            "[INFO|2025-06-09 08:20:18] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.\n",
            "[INFO|2025-06-09 08:20:18] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA\n",
            "[INFO|2025-06-09 08:20:18] llamafactory.model.model_utils.misc:143 >> Found linear modules: o_proj,up_proj,v_proj,gate_proj,q_proj,k_proj,down_proj\n",
            "[INFO|2025-06-09 08:20:18] llamafactory.model.loader:143 >> trainable params: 20,971,520 || all params: 7,268,995,072 || trainable%: 0.2885\n",
            "[INFO|trainer.py:756] 2025-06-09 08:20:18,614 >> Using auto half precision backend\n",
            "[INFO|trainer.py:2409] 2025-06-09 08:20:19,167 >> ***** Running training *****\n",
            "[INFO|trainer.py:2410] 2025-06-09 08:20:19,167 >>   Num examples = 464\n",
            "[INFO|trainer.py:2411] 2025-06-09 08:20:19,167 >>   Num Epochs = 5\n",
            "[INFO|trainer.py:2412] 2025-06-09 08:20:19,167 >>   Instantaneous batch size per device = 4\n",
            "[INFO|trainer.py:2415] 2025-06-09 08:20:19,167 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2416] 2025-06-09 08:20:19,167 >>   Gradient Accumulation steps = 4\n",
            "[INFO|trainer.py:2417] 2025-06-09 08:20:19,167 >>   Total optimization steps = 145\n",
            "[INFO|trainer.py:2418] 2025-06-09 08:20:19,172 >>   Number of trainable parameters = 20,971,520\n",
            "  3% 5/145 [03:19<1:34:10, 40.36s/it][INFO|2025-06-09 08:23:39] llamafactory.train.callbacks:143 >> {'loss': 1.7492, 'learning_rate': 4.9906e-05, 'epoch': 0.17, 'throughput': 48.66}\n",
            "{'loss': 1.7492, 'grad_norm': 5.438692569732666, 'learning_rate': 4.9906174282071535e-05, 'epoch': 0.17, 'num_input_tokens_seen': 9728, 'train_runtime': 199.9312, 'train_tokens_per_second': 48.657}\n",
            "  7% 10/145 [06:56<1:37:20, 43.26s/it][INFO|2025-06-09 08:27:15] llamafactory.train.callbacks:143 >> {'loss': 0.9412, 'learning_rate': 4.9526e-05, 'epoch': 0.34, 'throughput': 48.30}\n",
            "{'loss': 0.9412, 'grad_norm': 1.9899444580078125, 'learning_rate': 4.952621399215598e-05, 'epoch': 0.34, 'num_input_tokens_seen': 20128, 'train_runtime': 416.7253, 'train_tokens_per_second': 48.3}\n",
            " 10% 15/145 [10:27<1:28:58, 41.07s/it][INFO|2025-06-09 08:30:46] llamafactory.train.callbacks:143 >> {'loss': 0.8481, 'learning_rate': 4.8859e-05, 'epoch': 0.52, 'throughput': 48.23}\n",
            "{'loss': 0.8481, 'grad_norm': 1.8967186212539673, 'learning_rate': 4.8858706267713704e-05, 'epoch': 0.52, 'num_input_tokens_seen': 30240, 'train_runtime': 627.0395, 'train_tokens_per_second': 48.227}\n",
            " 14% 20/145 [14:01<1:28:02, 42.26s/it][INFO|2025-06-09 08:34:20] llamafactory.train.callbacks:143 >> {'loss': 0.7675, 'learning_rate': 4.7911e-05, 'epoch': 0.69, 'throughput': 48.12}\n",
            "{'loss': 0.7675, 'grad_norm': 1.745914340019226, 'learning_rate': 4.7911477026505654e-05, 'epoch': 0.69, 'num_input_tokens_seen': 40480, 'train_runtime': 841.2627, 'train_tokens_per_second': 48.118}\n",
            " 17% 25/145 [17:38<1:27:22, 43.69s/it][INFO|2025-06-09 08:37:57] llamafactory.train.callbacks:143 >> {'loss': 0.8107, 'learning_rate': 4.6696e-05, 'epoch': 0.86, 'throughput': 48.12}\n",
            "{'loss': 0.8107, 'grad_norm': 2.045872449874878, 'learning_rate': 4.669563166532503e-05, 'epoch': 0.86, 'num_input_tokens_seen': 50944, 'train_runtime': 1058.7125, 'train_tokens_per_second': 48.119}\n",
            " 21% 30/145 [21:01<1:19:43, 41.59s/it][INFO|2025-06-09 08:41:20] llamafactory.train.callbacks:143 >> {'loss': 0.7302, 'learning_rate': 4.5225e-05, 'epoch': 1.03, 'throughput': 48.09}\n",
            "{'loss': 0.7302, 'grad_norm': 1.5581731796264648, 'learning_rate': 4.522542485937369e-05, 'epoch': 1.03, 'num_input_tokens_seen': 60640, 'train_runtime': 1261.0647, 'train_tokens_per_second': 48.086}\n",
            " 24% 35/145 [24:29<1:14:38, 40.71s/it][INFO|2025-06-09 08:44:48] llamafactory.train.callbacks:143 >> {'loss': 0.6077, 'learning_rate': 4.3518e-05, 'epoch': 1.21, 'throughput': 48.07}\n",
            "{'loss': 0.6077, 'grad_norm': 1.8479446172714233, 'learning_rate': 4.351809343922848e-05, 'epoch': 1.21, 'num_input_tokens_seen': 70656, 'train_runtime': 1469.7627, 'train_tokens_per_second': 48.073}\n",
            " 28% 40/145 [28:06<1:14:26, 42.54s/it][INFO|2025-06-09 08:48:25] llamafactory.train.callbacks:143 >> {'loss': 0.5921, 'learning_rate': 4.1594e-05, 'epoch': 1.38, 'throughput': 48.09}\n",
            "{'loss': 0.5921, 'grad_norm': 1.8004651069641113, 'learning_rate': 4.159365430476261e-05, 'epoch': 1.38, 'num_input_tokens_seen': 81088, 'train_runtime': 1686.1466, 'train_tokens_per_second': 48.091}\n",
            " 31% 45/145 [31:29<1:08:34, 41.14s/it][INFO|2025-06-09 08:51:49] llamafactory.train.callbacks:143 >> {'loss': 0.5913, 'learning_rate': 3.9475e-05, 'epoch': 1.55, 'throughput': 48.07}\n",
            "{'loss': 0.5913, 'grad_norm': 2.271991014480591, 'learning_rate': 3.9474669745296225e-05, 'epoch': 1.55, 'num_input_tokens_seen': 90848, 'train_runtime': 1889.8323, 'train_tokens_per_second': 48.072}\n",
            " 34% 50/145 [35:05<1:08:43, 43.41s/it][INFO|2025-06-09 08:55:24] llamafactory.train.callbacks:143 >> {'loss': 0.5405, 'learning_rate': 3.7186e-05, 'epoch': 1.72, 'throughput': 48.05}\n",
            "{'loss': 0.5405, 'grad_norm': 2.0252840518951416, 'learning_rate': 3.718598291738298e-05, 'epoch': 1.72, 'num_input_tokens_seen': 101152, 'train_runtime': 2105.0335, 'train_tokens_per_second': 48.052}\n",
            " 38% 55/145 [38:36<1:03:20, 42.22s/it][INFO|2025-06-09 08:58:55] llamafactory.train.callbacks:143 >> {'loss': 0.5567, 'learning_rate': 3.4754e-05, 'epoch': 1.90, 'throughput': 48.07}\n",
            "{'loss': 0.5567, 'grad_norm': 2.449718713760376, 'learning_rate': 3.4754426581513866e-05, 'epoch': 1.9, 'num_input_tokens_seen': 111360, 'train_runtime': 2316.7955, 'train_tokens_per_second': 48.066}\n",
            " 41% 60/145 [42:06<59:35, 42.07s/it]  [INFO|2025-06-09 09:02:25] llamafactory.train.callbacks:143 >> {'loss': 0.4588, 'learning_rate': 3.2209e-05, 'epoch': 2.07, 'throughput': 48.05}\n",
            "{'loss': 0.4588, 'grad_norm': 1.8565820455551147, 'learning_rate': 3.220850851253377e-05, 'epoch': 2.07, 'num_input_tokens_seen': 121376, 'train_runtime': 2526.2202, 'train_tokens_per_second': 48.046}\n",
            " 45% 65/145 [45:30<54:15, 40.69s/it][INFO|2025-06-09 09:05:49] llamafactory.train.callbacks:143 >> {'loss': 0.4107, 'learning_rate': 2.9578e-05, 'epoch': 2.24, 'throughput': 48.04}\n",
            "{'loss': 0.4107, 'grad_norm': 2.1080737113952637, 'learning_rate': 2.9578077272046408e-05, 'epoch': 2.24, 'num_input_tokens_seen': 131168, 'train_runtime': 2730.2432, 'train_tokens_per_second': 48.043}\n",
            " 48% 70/145 [48:55<50:59, 40.79s/it][INFO|2025-06-09 09:09:14] llamafactory.train.callbacks:143 >> {'loss': 0.3940, 'learning_rate': 2.6894e-05, 'epoch': 2.41, 'throughput': 48.05}\n",
            "{'loss': 0.394, 'grad_norm': 2.724414348602295, 'learning_rate': 2.6893972261320266e-05, 'epoch': 2.41, 'num_input_tokens_seen': 141056, 'train_runtime': 2935.6818, 'train_tokens_per_second': 48.049}\n",
            " 52% 75/145 [52:24<48:46, 41.81s/it][INFO|2025-06-09 09:12:44] llamafactory.train.callbacks:143 >> {'loss': 0.3576, 'learning_rate': 2.4188e-05, 'epoch': 2.59, 'throughput': 48.04}\n",
            "{'loss': 0.3576, 'grad_norm': 2.8465964794158936, 'learning_rate': 2.418766215750549e-05, 'epoch': 2.59, 'num_input_tokens_seen': 151072, 'train_runtime': 3144.9445, 'train_tokens_per_second': 48.036}\n",
            " 55% 80/145 [55:59<47:02, 43.42s/it][INFO|2025-06-09 09:16:18] llamafactory.train.callbacks:143 >> {'loss': 0.3702, 'learning_rate': 2.1491e-05, 'epoch': 2.76, 'throughput': 48.07}\n",
            "{'loss': 0.3702, 'grad_norm': 2.498995304107666, 'learning_rate': 2.1490875972166395e-05, 'epoch': 2.76, 'num_input_tokens_seen': 161504, 'train_runtime': 3359.506, 'train_tokens_per_second': 48.074}\n",
            " 59% 85/145 [59:26<41:44, 41.75s/it][INFO|2025-06-09 09:19:45] llamafactory.train.callbacks:143 >> {'loss': 0.3385, 'learning_rate': 1.8835e-05, 'epoch': 2.93, 'throughput': 48.06}\n",
            "{'loss': 0.3385, 'grad_norm': 2.5004842281341553, 'learning_rate': 1.8835231057630953e-05, 'epoch': 2.93, 'num_input_tokens_seen': 171424, 'train_runtime': 3566.6625, 'train_tokens_per_second': 48.063}\n",
            " 62% 90/145 [1:02:54<38:24, 41.90s/it][INFO|2025-06-09 09:23:14] llamafactory.train.callbacks:143 >> {'loss': 0.3259, 'learning_rate': 1.6252e-05, 'epoch': 3.10, 'throughput': 48.04}\n",
            "{'loss': 0.3259, 'grad_norm': 2.392599105834961, 'learning_rate': 1.625186242244279e-05, 'epoch': 3.1, 'num_input_tokens_seen': 181344, 'train_runtime': 3774.9515, 'train_tokens_per_second': 48.039}\n",
            " 66% 95/145 [1:06:20<34:12, 41.06s/it][INFO|2025-06-09 09:26:39] llamafactory.train.callbacks:143 >> {'loss': 0.2429, 'learning_rate': 1.3771e-05, 'epoch': 3.28, 'throughput': 48.05}\n",
            "{'loss': 0.2429, 'grad_norm': 2.2741637229919434, 'learning_rate': 1.3771057701853032e-05, 'epoch': 3.28, 'num_input_tokens_seen': 191232, 'train_runtime': 3980.1438, 'train_tokens_per_second': 48.047}\n",
            " 69% 100/145 [1:09:46<30:20, 40.45s/it][INFO|2025-06-09 09:30:05] llamafactory.train.callbacks:143 >> {'loss': 0.2463, 'learning_rate': 1.1422e-05, 'epoch': 3.45, 'throughput': 48.05}\n",
            "{'loss': 0.2463, 'grad_norm': 2.6452536582946777, 'learning_rate': 1.1421902062989179e-05, 'epoch': 3.45, 'num_input_tokens_seen': 201184, 'train_runtime': 4186.8176, 'train_tokens_per_second': 48.052}\n",
            " 69% 100/145 [1:09:46<30:20, 40.45s/it][INFO|trainer.py:4327] 2025-06-09 09:30:05,996 >> \n",
            "***** Running Evaluation *****\n",
            "[INFO|trainer.py:4329] 2025-06-09 09:30:05,996 >>   Num examples = 52\n",
            "[INFO|trainer.py:4332] 2025-06-09 09:30:05,996 >>   Batch size = 4\n",
            "\n",
            "  0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            " 15% 2/13 [00:03<00:18,  1.65s/it]\u001b[A\n",
            " 23% 3/13 [00:07<00:25,  2.52s/it]\u001b[A\n",
            " 31% 4/13 [00:09<00:24,  2.68s/it]\u001b[A\n",
            " 38% 5/13 [00:13<00:23,  2.90s/it]\u001b[A\n",
            " 46% 6/13 [00:16<00:21,  3.03s/it]\u001b[A\n",
            " 54% 7/13 [00:19<00:18,  3.01s/it]\u001b[A\n",
            " 62% 8/13 [00:23<00:16,  3.34s/it]\u001b[A\n",
            " 69% 9/13 [00:26<00:12,  3.23s/it]\u001b[A\n",
            " 77% 10/13 [00:30<00:10,  3.38s/it]\u001b[A\n",
            " 85% 11/13 [00:34<00:06,  3.49s/it]\u001b[A\n",
            " 92% 12/13 [00:38<00:03,  3.79s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.7198848724365234, 'eval_runtime': 44.8347, 'eval_samples_per_second': 1.16, 'eval_steps_per_second': 0.29, 'epoch': 3.45, 'num_input_tokens_seen': 201184}\n",
            " 69% 100/145 [1:10:31<30:20, 40.45s/it]\n",
            "100% 13/13 [00:41<00:00,  3.54s/it]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:3993] 2025-06-09 09:30:50,828 >> Saving model checkpoint to saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55/checkpoint-100\n",
            "[INFO|configuration_utils.py:698] 2025-06-09 09:30:51,401 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/config.json\n",
            "[INFO|configuration_utils.py:770] 2025-06-09 09:30:51,402 >> Model config MistralConfig {\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": null,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32768\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2356] 2025-06-09 09:30:51,561 >> chat template saved in saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55/checkpoint-100/chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2525] 2025-06-09 09:30:51,568 >> tokenizer config file saved in saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55/checkpoint-100/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2534] 2025-06-09 09:30:51,568 >> Special tokens file saved in saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55/checkpoint-100/special_tokens_map.json\n",
            " 72% 105/145 [1:14:15<30:19, 45.49s/it][INFO|2025-06-09 09:34:34] llamafactory.train.callbacks:143 >> {'loss': 0.2712, 'learning_rate': 9.2319e-06, 'epoch': 3.62, 'throughput': 47.49}\n",
            "{'loss': 0.2712, 'grad_norm': 3.373673677444458, 'learning_rate': 9.231937207863459e-06, 'epoch': 3.62, 'num_input_tokens_seen': 211584, 'train_runtime': 4455.6349, 'train_tokens_per_second': 47.487}\n",
            " 76% 110/145 [1:17:47<25:28, 43.66s/it][INFO|2025-06-09 09:38:06] llamafactory.train.callbacks:143 >> {'loss': 0.2250, 'learning_rate': 7.2268e-06, 'epoch': 3.79, 'throughput': 47.52}\n",
            "{'loss': 0.225, 'grad_norm': 2.9245409965515137, 'learning_rate': 7.226838472098238e-06, 'epoch': 3.79, 'num_input_tokens_seen': 221792, 'train_runtime': 4667.4108, 'train_tokens_per_second': 47.519}\n",
            " 79% 115/145 [1:21:12<20:56, 41.89s/it][INFO|2025-06-09 09:41:32] llamafactory.train.callbacks:143 >> {'loss': 0.2395, 'learning_rate': 5.4301e-06, 'epoch': 3.97, 'throughput': 47.52}\n",
            "{'loss': 0.2395, 'grad_norm': 3.23415470123291, 'learning_rate': 5.430113805091111e-06, 'epoch': 3.97, 'num_input_tokens_seen': 231584, 'train_runtime': 4872.9143, 'train_tokens_per_second': 47.525}\n",
            " 83% 120/145 [1:24:37<16:53, 40.54s/it][INFO|2025-06-09 09:44:56] llamafactory.train.callbacks:143 >> {'loss': 0.2136, 'learning_rate': 3.8628e-06, 'epoch': 4.14, 'throughput': 47.54}\n",
            "{'loss': 0.2136, 'grad_norm': 2.890029191970825, 'learning_rate': 3.862828160801707e-06, 'epoch': 4.14, 'num_input_tokens_seen': 241376, 'train_runtime': 5077.358, 'train_tokens_per_second': 47.54}\n",
            " 86% 125/145 [1:28:10<14:08, 42.42s/it][INFO|2025-06-09 09:48:29] llamafactory.train.callbacks:143 >> {'loss': 0.1674, 'learning_rate': 2.5434e-06, 'epoch': 4.31, 'throughput': 47.56}\n",
            "{'loss': 0.1674, 'grad_norm': 2.455031633377075, 'learning_rate': 2.543356530426394e-06, 'epoch': 4.31, 'num_input_tokens_seen': 251648, 'train_runtime': 5290.8, 'train_tokens_per_second': 47.563}\n",
            " 90% 130/145 [1:31:34<10:21, 41.40s/it][INFO|2025-06-09 09:51:53] llamafactory.train.callbacks:143 >> {'loss': 0.1870, 'learning_rate': 1.4872e-06, 'epoch': 4.48, 'throughput': 47.58}\n",
            "{'loss': 0.187, 'grad_norm': 2.7745673656463623, 'learning_rate': 1.4871685124269008e-06, 'epoch': 4.48, 'num_input_tokens_seen': 261408, 'train_runtime': 5494.1533, 'train_tokens_per_second': 47.579}\n",
            " 93% 135/145 [1:35:09<07:12, 43.24s/it][INFO|2025-06-09 09:55:28] llamafactory.train.callbacks:143 >> {'loss': 0.2053, 'learning_rate': 7.0665e-07, 'epoch': 4.66, 'throughput': 47.59}\n",
            "{'loss': 0.2053, 'grad_norm': 2.3734147548675537, 'learning_rate': 7.06646945632361e-07, 'epoch': 4.66, 'num_input_tokens_seen': 271712, 'train_runtime': 5709.2667, 'train_tokens_per_second': 47.591}\n",
            " 97% 140/145 [1:38:33<03:31, 42.23s/it][INFO|2025-06-09 09:58:52] llamafactory.train.callbacks:143 >> {'loss': 0.2000, 'learning_rate': 2.1094e-07, 'epoch': 4.83, 'throughput': 47.61}\n",
            "{'loss': 0.2, 'grad_norm': 2.3741350173950195, 'learning_rate': 2.1094273177576507e-07, 'epoch': 4.83, 'num_input_tokens_seen': 281504, 'train_runtime': 5913.2643, 'train_tokens_per_second': 47.606}\n",
            "100% 145/145 [1:42:04<00:00, 42.24s/it][INFO|2025-06-09 10:02:23] llamafactory.train.callbacks:143 >> {'loss': 0.1813, 'learning_rate': 5.8675e-09, 'epoch': 5.00, 'throughput': 47.62}\n",
            "{'loss': 0.1813, 'grad_norm': 2.7488276958465576, 'learning_rate': 5.86754953789681e-09, 'epoch': 5.0, 'num_input_tokens_seen': 291648, 'train_runtime': 6124.0838, 'train_tokens_per_second': 47.623}\n",
            "100% 145/145 [1:42:04<00:00, 42.24s/it][INFO|trainer.py:3993] 2025-06-09 10:02:23,257 >> Saving model checkpoint to saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55/checkpoint-145\n",
            "[INFO|configuration_utils.py:698] 2025-06-09 10:02:23,929 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/config.json\n",
            "[INFO|configuration_utils.py:770] 2025-06-09 10:02:23,930 >> Model config MistralConfig {\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": null,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32768\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2356] 2025-06-09 10:02:24,080 >> chat template saved in saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55/checkpoint-145/chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2525] 2025-06-09 10:02:24,087 >> tokenizer config file saved in saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55/checkpoint-145/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2534] 2025-06-09 10:02:24,088 >> Special tokens file saved in saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55/checkpoint-145/special_tokens_map.json\n",
            "[INFO|trainer.py:2676] 2025-06-09 10:02:31,010 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 6131.8389, 'train_samples_per_second': 0.378, 'train_steps_per_second': 0.024, 'train_loss': 0.47484432212237654, 'epoch': 5.0, 'num_input_tokens_seen': 291648}\n",
            "100% 145/145 [1:42:11<00:00, 42.29s/it]\n",
            "[INFO|trainer.py:3993] 2025-06-09 10:02:31,012 >> Saving model checkpoint to saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55\n",
            "[INFO|configuration_utils.py:698] 2025-06-09 10:02:31,556 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/config.json\n",
            "[INFO|configuration_utils.py:770] 2025-06-09 10:02:31,557 >> Model config MistralConfig {\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": null,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32768\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2356] 2025-06-09 10:02:31,880 >> chat template saved in saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55/chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2525] 2025-06-09 10:02:31,891 >> tokenizer config file saved in saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2534] 2025-06-09 10:02:31,892 >> Special tokens file saved in saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        5.0\n",
            "  num_input_tokens_seen    =     291648\n",
            "  total_flos               = 11627619GF\n",
            "  train_loss               =     0.4748\n",
            "  train_runtime            = 1:42:11.83\n",
            "  train_samples_per_second =      0.378\n",
            "  train_steps_per_second   =      0.024\n",
            "Figure saved at: saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55/training_loss.png\n",
            "Figure saved at: saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55/training_eval_loss.png\n",
            "[WARNING|2025-06-09 10:02:32] llamafactory.extras.ploting:148 >> No metric eval_accuracy to plot.\n",
            "[INFO|trainer.py:4327] 2025-06-09 10:02:32,281 >> \n",
            "***** Running Evaluation *****\n",
            "[INFO|trainer.py:4329] 2025-06-09 10:02:32,282 >>   Num examples = 52\n",
            "[INFO|trainer.py:4332] 2025-06-09 10:02:32,282 >>   Batch size = 4\n",
            "100% 13/13 [00:42<00:00,  3.24s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        5.0\n",
            "  eval_loss               =     0.7454\n",
            "  eval_runtime            = 0:00:45.48\n",
            "  eval_samples_per_second =      1.143\n",
            "  eval_steps_per_second   =      0.286\n",
            "  num_input_tokens_seen   =     291648\n",
            "[INFO|modelcard.py:450] 2025-06-09 10:03:17,761 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:06:25,677 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:06:25,678 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:06:25,678 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:06:25,678 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:06:25,678 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:06:25,678 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|configuration_utils.py:698] 2025-06-09 10:06:27,607 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/config.json\n",
            "[INFO|configuration_utils.py:770] 2025-06-09 10:06:27,619 >> Model config MistralConfig {\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": null,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32768\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:06:28,123 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:06:28,123 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:06:28,123 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:06:28,123 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:06:28,123 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:06:28,123 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|2025-06-09 10:06:28] llamafactory.data.template:143 >> Add pad token: </s>\n",
            "[INFO|configuration_utils.py:698] 2025-06-09 10:06:28,788 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/config.json\n",
            "[INFO|configuration_utils.py:770] 2025-06-09 10:06:28,789 >> Model config MistralConfig {\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": null,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32768\n",
            "}\n",
            "\n",
            "[INFO|2025-06-09 10:06:28] llamafactory.model.model_utils.quantization:143 >> Quantizing model to 4 bit with bitsandbytes.\n",
            "[INFO|2025-06-09 10:06:28] llamafactory.model.model_utils.kv_cache:143 >> KV cache is enabled for faster generation.\n",
            "[INFO|modeling_utils.py:1151] 2025-06-09 10:06:29,793 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/model.safetensors.index.json\n",
            "[INFO|modeling_utils.py:2241] 2025-06-09 10:06:29,793 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:1135] 2025-06-09 10:06:29,795 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2\n",
            "}\n",
            "\n",
            "Loading checkpoint shards: 100% 3/3 [01:51<00:00, 37.18s/it]\n",
            "[INFO|modeling_utils.py:5131] 2025-06-09 10:08:21,516 >> All model checkpoint weights were used when initializing MistralForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:5139] 2025-06-09 10:08:21,516 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at mistralai/Mistral-7B-Instruct-v0.3.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n",
            "[INFO|configuration_utils.py:1090] 2025-06-09 10:08:21,763 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/generation_config.json\n",
            "[INFO|configuration_utils.py:1135] 2025-06-09 10:08:21,763 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2\n",
            "}\n",
            "\n",
            "[INFO|2025-06-09 10:08:22] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
            "[INFO|2025-06-09 10:08:23] llamafactory.model.adapter:143 >> Loaded adapter(s): saves/Mistral-7B-Instruct-v0.3/lora/train_2025-06-09-08-02-55\n",
            "[INFO|2025-06-09 10:08:23] llamafactory.model.loader:143 >> all params: 7,268,995,072\n",
            "[WARNING|2025-06-09 10:08:23] llamafactory.chat.hf_engine:154 >> There is no current event loop, creating a new one.\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:28:36,905 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:28:36,905 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:28:36,906 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:28:36,906 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:28:36,906 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:28:36,906 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|configuration_utils.py:698] 2025-06-09 10:28:38,930 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/config.json\n",
            "[INFO|configuration_utils.py:770] 2025-06-09 10:28:38,931 >> Model config MistralConfig {\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": null,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32768\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:28:39,433 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:28:39,433 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:28:39,434 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:28:39,434 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:28:39,434 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2023] 2025-06-09 10:28:39,434 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|2025-06-09 10:28:39] llamafactory.data.template:143 >> Add pad token: </s>\n",
            "[INFO|configuration_utils.py:698] 2025-06-09 10:28:40,085 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/config.json\n",
            "[INFO|configuration_utils.py:770] 2025-06-09 10:28:40,085 >> Model config MistralConfig {\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": null,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32768\n",
            "}\n",
            "\n",
            "[INFO|2025-06-09 10:28:40] llamafactory.model.model_utils.kv_cache:143 >> KV cache is enabled for faster generation.\n",
            "[INFO|modeling_utils.py:1151] 2025-06-09 10:28:40,087 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/model.safetensors.index.json\n",
            "[INFO|modeling_utils.py:2241] 2025-06-09 10:28:40,097 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:1135] 2025-06-09 10:28:40,098 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2\n",
            "}\n",
            "\n",
            "Loading checkpoint shards: 100% 3/3 [00:00<00:00,  5.44it/s]\n",
            "[INFO|modeling_utils.py:5131] 2025-06-09 10:28:40,692 >> All model checkpoint weights were used when initializing MistralForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:5139] 2025-06-09 10:28:40,692 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at mistralai/Mistral-7B-Instruct-v0.3.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n",
            "[INFO|configuration_utils.py:1090] 2025-06-09 10:28:40,971 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/e0bc86c23ce5aae1db576c8cca6f06f1f73af2db/generation_config.json\n",
            "[INFO|configuration_utils.py:1135] 2025-06-09 10:28:40,972 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2\n",
            "}\n",
            "\n",
            "[INFO|2025-06-09 10:28:41] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xcbUb2PtrgQC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vDrLeWbBrgNd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dknMAOntrgK0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B4y5QKiLrgIO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kW906dcprgFL"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}